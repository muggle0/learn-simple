---
title: muggle 的后端笔记
date: 2019-08-02 20:36:40
tags: home

---

作者: muggle

# 序



感谢阅读。
2019年8月

<!--more-->

# 目录

[TOC]

# 1. MySQL

## 1.1 mysql 架构

mysql分为server层和存储引擎

### 1.1.1  server层

- 连接器：管理连接权限验证
- 查询缓存：命中缓存直接换回查询结果
- 分析器：分析语法
- 优化器：生成执行计划，选择索引
- 执行器：操作索引返回结果

### 1.1.2  存储引擎

存储引擎负责数据的存储和提取；其架构是插件式的。innodb在mysql5.5.5版本开始成为mysql默认存储引擎。

各存储引擎比对：

- InnoDB：支持事务，支持外键，InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据，不支持全文索引。
- MyISAM：不支持事物，不支持外键，MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的，查询效率上MyISAM要高于InnnDB，因此做读写分离的时候一般选择用InnoDB做主机，MyISAM做从机
- Memory：有比较大的缺陷使用场景很少；文件数据都存储在内存中，如果mysqld进程发生异常，重启或关闭机器这些数据都会消失。

### 1.1.3 sql的执行过程

第一步客户端连接上mysql数据库的连接器，连接器获取权限，维持管理连接；连接完成后如果你没有后续的指令这个连接就会处于空闲状态，如果太长时间不使用这个连接这个连接就会断开，这个空闲时长默认是8小时，由wait_timeout参数控制。

第二步你往mysql数据库发送了一条sql，这个时候查询缓存开始工作，看看之前有没有执行过这个sql，如果有则直接返回缓存数据到客户端，只要对表执行过更新操作缓存都会失效，因此一些很少更新的数据表可考虑使用数据库缓存，对频繁更新的表使用缓存反而弊大于利。使用缓存的方法如以下sql，通过SQL_CACHE来指定：

```sql
select  SQL_CACHE * from table where xxx=xxx
```

第三步当未命中缓存的时候，分析器开始工作；分析器判断你是select还是update还是insert，分析你的语法是否正确。

第四步优化器根据你的表的索引和sql语句决定用哪个索引，决定join的顺序。

第五步执行器执行sql，调用存储引擎的接口，扫描遍历表或者插入更新数据。

## 1.2 mysql日志

### 1.2.1 mysql日志介绍

mysql有两个重要日志——redolog和binlog(还有一个undolog不做介绍)，redolog是独属于innodb的日志，binlog则是属于server层的日志。下面介绍这两个日志有什么用：当我们更新数据库数据的时候，这两个日志文件也会被更新，记录数据库更新操作。

redolog又称作重做日志，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。它在数据库重启恢复的时候被使用，innodb利用这个日志恢复到数据库宕机前的状态，以此来保证数据的完整性。redolog是物理日志，记录的是某个表的数据做了哪些修改，redolog是固定大小的，也就是说后面的日志会覆盖前面的日志。

binlog又称作归档日志，它记录了对MySQL数据库执行更改的所有操作，但是不包括SELECT和SHOW这类操作。binlog是逻辑日志，记录的是某个表执行了哪些操作。binlog是追加形式的写入日志，后面的日志不会被前面的覆盖

### 1.2.2  数据更新过程

我们执行一个更新操作是这样的：读取对应的数据到内存—>更新数据—>写redolog日志—>redolog状态为prepare—>写binlog日志—>提交事务—>redolog状态为commit，数据正式写入日志文件。我们发现redolog的提交方式为“两段式提交”，这样做的目的是为了数据恢复的时候确保数据恢复的准确性，因为数据恢复是通过备份的binlog来完成的，所以要确保redolog要和binlog一致。

## 1.3 mysql的mvcc

事务隔离级别在此略过，相信大部分小伙伴都知道相关的知识了，在这里单单只介绍mysql实现事务隔离的原理——mvcc(多版本并发控制)。在学习mvcc之前我需要先介绍快照读和当前读。

### 1.3.1 快照读和当前读

快照读就是一个`select`语句，形如：

```sql
select * from table
```

在`Repeatable read`事务隔离级别下，快照读的特点是获取当前数据库的快照数据，对于所有未commit的数据都不可见，快照读不会对数据上锁。

当前读是对所读数据上悲观锁使其他当前读无法操作数据。当前读sql包括:

```java
select ... lock in share mode

select ... for update

insert

update

delete
```

其中后面三个sql都是给数据库上排他锁（X锁），而第一个sql是给数据库上共享锁（S锁）。X锁是一旦某个当前读到这个锁，其他当前读则没有对这个事务读写的权利，其他当前读会被阻塞住。而S锁是当一个当前读对某条数据上S锁，其他当前读可以对该数据也上S锁但不能上X锁，拿到S锁的当前读可以读数据不能改数据。（关于数据库悲观锁乐观锁并发章节会介绍）。

### 1.3.2 mvcc原理

innodb实现快照读和当 前读悲观锁的技术就是mvcc。innodb在插入一条数据的时候会在后面跟上两个隐藏的列，这两个列，一个保存了这个行的创建时系统版本号，一个保存的是行的删除的系统版本号。每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID。innodb更新一条数据是设置旧数据删除版本号，然后插入一条新的数据并设置创建版本号，然后删除旧的数据。那么怎么保证快照读是读取到未commit的数据呢，两个条件：

- InnoDB只查找创建版本早于当前事务版本的数据行，即，行的系统版本号小于或等于事务的系统版本号，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。
- 行的删除版本，要么未定义，要么大于当前事务版本号。这样可以确保事务读取到的行，在事务开始之前未被删除。
  只有符合上述两个条件的纪录，才能作为查询结果返回。

而数据库锁也是通过比对版本号来决定是否阻塞某个事物。

## 1.4 mysql 索引 

### 1.4.1  索引介绍

索引按数据结构分可分为哈希表，有序数组，搜索树，跳表：

- 哈希表适用于只有等值查询的场景
- 有序数组适用于有等值查询和范围查询的场景，但有序数组索引的更新代价很大，所以最好用于静态数据表
- 搜索树的搜索效率稳定，不会出现大幅波动，而且基于索引的顺序扫描时，也可以利用双向指针快速左右移动，效率非常高
- 跳表可以理解为优化的哈希索引

innodb使用了B+树索引模型，而且是多叉树。虽然二叉树是索引效率最高的，但是索引需要写入磁盘，如果使用二叉树磁盘io会变得很频繁。在innodb索引中分为主键索引（聚簇索引）和非主键索引（二级索引）。主键索引保存了该行数据的全部信息，二级索引保存了该行数据的主键；所以使用二级索引的时候会先查出主键值，然后回表查询出数据，而使用主键索引则不需要回表。

对二级索引而言可使用覆盖索引来优化sql，看下面两条sql

```sql
select * from table where key=1;
select id from table where key=1;
```

key是一个二级索引，第一条sql是先查询出id，然后根据id回表查询出真正的数据。而第二条查询索引后直接返回数据不需要回表。第二条sql索引key覆盖了我们的查询需求，称作覆盖索引

### 1.4.2 普通索引和唯一索引

innoDB是按数据页来读写数据的，当要读取一条数据的时候是先将本页数据全部读入内存，然后找到对应数据，而不是直接读取，每页数据的默认大小为16KB。

当一个数据页需要更新的时候，如果内存中有该数据页就直接更新，如果没有该数据页则在不影响数据一致性的前提下将；更新操作先缓存到`change buffer`中，在下次查询需要访问这个数据页的时候再写入更新操作除了查询会将`change buffer` 写入磁盘，后台线程线程也会定期将`change buffer`写入到磁盘中。对于唯一索引来说所有的更新操作都要先判断这个操作是否会违反唯一性约束，因此唯一索引的更新无法使用`change buffer` 而普通索引可以，唯一索引更新比普通索引更新多一个唯一性校验的过程。

### 1.4.3 联合索引  

两个或更多个列上的索引被称作联合索引（复合索引）。联合索引可减少索引开销，以联合索引(a,b,c)为例，建立这样的索引相当于建立了索引a、ab、abc三个索引——Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分，而且当最左侧字段是常量引用时，索引就十分有效，这就是**最左前缀原则**。由最左前缀原则可知，组合索引是有顺序的，那么哪个索引放在前面就比较有讲究了。对于组合索引还有一个知识点——**索引下推**，假设有组合索引（a，b，c）有如下sql:

```sql
selet * from table where a=xxx and b=xxx
```

这个sql会进行两次筛选第一次查出`a=xxx`数据 再从`a=xxx`中查出 `b=xxx` 的数据。使用索引下推和不使用索引下推的区别在于不使用索引下推会先查出`a=xxx`数据的主键然后根据查询出的主键回表查询出全行数据，再在全行数据上查出 `b=xxx` 的数据；而索引下推的执行过程是先查出`a=xxx`数据的主键，然后在这些主键上二次查询 `b=xxx` 的主键，然后回表。

索引下推的特点：

- innodb引擎的表，索引下推只能用于二级索引
- 索引下推一般可用于所查询字段不全是联合索引的字段，查询条件为多条件查询且查询条件子句字段全是联合索引。



### 1.4.4 优化器与索引

在 索引建立之后，一条语句可能会命中多个索引，这时，就会交由优化器来选择合适的索引。优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。那么优化器是怎么去确定索引的呢？优化器会优先选择扫描行数最少的索引，同时还会结合是否使用临时表、是否排序等因素进行综合判断。MySQL 在开始执行sql之前，并不知道满足这个条件的记录有多少条，而只能根据mysql的统计信息来估计，而统计信息是通过数据采样得出来的。

### 1.4.5 其他索引知识点

有时候需要索引很长的字符列，这会让索引变得很大很慢还占内存。通常可以以开始的部分字符作为索引，这就是**前缀索引**。这样可以大大节约索引空间，从而提高索引效率，但这样也会降低索引的选择性。

**脏页**对数据库的影响：

当内存数据页和磁盘的数据不一致的时候我们称这个内存页为脏页，内存数据写入磁盘后数据一致，称为干净页。当要读入数据而数据库没有内存的时候，这个时候需要淘汰内存中的数据页——干净页可以直接淘汰掉，而脏页需要先刷入磁盘再淘汰。如果一个查询要淘汰的脏页太多会导致查询的时间变长。为了减少脏页对数据库性能影响，innodb会控制脏页的比例和脏页刷新时机。

## 1.5 mysql语法分析及优化

### 1.5.1 count(*)

`count(*)`对innodb而言，它需要把数据从磁盘中读取出来然后累计计数；而MyISAM引擎把一个表的总行数存在了磁盘上，所以执行`count(*)`会直接返回这个数，如果有where条件则和innodb一样。
那么如何优化`count(*)`？一个思路是使用缓存，但是需要注意双写一致的问题（双写一致性后文缓存章节会做介绍）。还可以专门设计一张表用以存储`count(*)`。

对于count(主键id)来说，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server 层。server层拿到id后，判断是不可能为空的，就按行累加。 对于count(1)来说，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个 数字“1”进去，判断是不可能为空的，按行累加。 单看这两个用法的差别的话，你能对比出来，count(1)执行得要比count(主键id)快。因为从引擎 返回id会涉及到解析数据行，以及拷贝字段值的操作。 对于count(字段)来说： 如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加； 如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再 判断一下，不是null才累加。  而对于count(*)来说，并不会把全部字段取出来，而是专门做了优化，不取值，按行累加。所以排序效率：
> count(*)=count(1)>count(id)>count(字段)


### 1.5.2 order by

Mysql会给每个线程分配一块内存用于做排序处理，称为`sort_buffer`,一个包含排序的sql执行过程为：申请排序内存`sort_buffer`,然后一条条查询出整行数据，然后将需要的字段数据放入到排序内存中，染回对排序内存中的数据做一个快速排序，然后返回到客户端。当数据量过大，排序内存盛不下的时候就会利用磁盘临时文件来辅助排序。当我们排序内存盛不下数据的时候，mysql会使用`rowid`排序来优化。rowid排序相对于全字段排序，不会把所有字段都放入sort_buffer，所以在sort buffer中进行排序之后还得回表查询。在少数情况下，可以使用联合索引+索引覆盖的方式来优化order by。

### 1.5.3 join
在了解`join`之前我们应该先了解**驱动表**这个概念——当两表发生关联的时候就会有驱动表和被驱动表之分，驱动表也叫外表（R表），被驱动表也叫做内表（S表）。一般我们将小表当做驱动表（指定了联接条件时，满足查询条件的记录行数少的表为「驱动表」,未指定联接条件时，行数少的表为「驱动表」；MySQL 内部优化器也是这么做的）。

假设有这样一句sql（xxx 为索引）:
```sql
select * from table1 left join tablet2 on table1.xxx=table2.xxx 
```
这条语句执行过程是先遍历表table1，然后根据从表table1中取出的每行数据中的xxx值，去表table2中查找满足条件的 记录。这个过程就跟我们写程序时的嵌套查询类似，并且能够用上被驱动表的索引，这种查询方式叫`NLJ`。当xxx不是索引的时候，再使用`NLJ`的话就会对table2做多次的全表扫描（每从table1取一条数据就全表扫描一次table2），扫描数暴涨。这个时候mysql会采用另外一个查询策略。Mysql会先把table1的数据读入到一个`join_buffer`的内存空间里面去，然后
依次取出table2的每一行数据，跟`join_buffer`中的数据做对比，满足join条件的作为结果集的一部分返回。
我们在使用`join`的时候,要遵循以下几点：
- 小表驱动大表。
- 被驱动表走索引的情况下（走`NLJ`查询方式）的时候才考虑用join


### 1.5.4 sql的优化 
1） 在mysql中，如果对字段做了函数计算，就用不上索引了
如以下sql(data 为索引):
```sql
select *  from tradelog where month(data)=1;
```
优化器对这样的sql会放弃走搜索树，因为它无法知道data的区间。

2）隐式的类型转换会导致索引失效。
如以下sql:
```sql
select * from table where xxx=110717;
```
其中xxx为`varchar`型，在mysql中，字符串和数字做比较的话，将字符串转换成数字再进行比较，这里相当于使用了`CAST(xxx AS signed )` 导致无法走索引。

3）索引列参与了计算不会走索引

4）like %xxx 不会走索引，like xxx% 会走索引

5）在where子句中使用or，在innodb中不会走索引，而MyISAM会。


## 1.6执行计划和慢查询日志
### 1.6.1 执行计划
在查询sql之前加上`explain`可查看该条sql的执行计划,如：
```sql
EXPLAIN SELECT * FROM table
```
这条sql会返回这样一个表：

id | select_type|table|partitions|type|possible_keys|key|key_len|ref|rows|filtered|extra|
---| ---------|-----|------------|----|-------------|---|-------|---|----|----|----|
1 | simple
这个表便是sql的执行计划，我们可以通过分析这个执行计划来知道我们sql的运行情况。现对各列进行解释：

1）id：查询中执行select子句或操作表的顺序。

2）select_type：查询中每个select子句的类型（简单 到复杂）包括：
- SIMPLE：查询中不包含子查询或者UNION；
- PRIMARY：查询中包含复杂的子部分；
- SUBQUERY：在SELECT或WHERE列表中包含了子查询，该子查询被标记为SUBQUERY；
- DERIVED：衍生，在FROM列表中包含的子查询被标记为DERIVED；
- UNION：若第二个SELECT出现在UNION之后，则被标记为UNION；
- UNION  RESULT：从UNION表获取结果的SELECT被标记为UNION RESULT；


3） type：表示MySQL在表中找到所需行的方式，又称“访问类型”，包括：
- ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行；
- index：Full Index Scan，index与ALL区别为index类型只遍历索引树；
- range：索引范围扫描，对索引的扫描开始于某一点，返回匹配值域的行，常见于between  <  >  等查询；
- ref：非唯一性索引扫描，返回匹配某个单独值的所有行。常见于使用非唯一索引即唯一索引的非唯一前缀进行的查找；
- eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描；
- onst 和 system：当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const类型的特例，当查询的表只有一行的情况下， 使用system；
- NULL：MySQL在优化过程中分解语句，执行时甚至不用访问表或索引。

4）possible_keys： 指出MySQL能使用哪个索引在表中找到行，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用。

5）key：显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。

6）key_len：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。

7）ref： 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值。

8）rows： 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值。

9）Extra：其他重要信息 包括：
- Using index：该值表示相应的select操作中使用了覆盖索引 ；
- Using where：MySQL将用where子句来过滤结果集；
- Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询；
- Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序”。

### 1.6.2 慢查询日志
mysql支持慢查询日志功能——mysql会将查询时间过长的sql相关信息写入日志。这个查询时间阀值由参数`long_query_time`指定，`long_query_time`的默认值为10，运行10S以上的查询sql会被记录到慢查询日志中。默认情况下，Mysql数据库并不启动慢查询日志，需要我们手动来设置这个参数。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。

可通过以下sql查看慢查询日志是否开启：
```sql
show variables  like '%slow_query_log%';
```
通过以下sql开启慢查询：
```sql
set global slow_query_log=1;
```
使用sql修改慢查询日志设置只对当前数据库生效，如果MySQL重启后则会失效。如果要永久生效，就必须修改配置文件my.cnf。

通过以下sql查看修改慢查询的阈值：
```sql
show variables like 'long_query_time%';
set global long_query_time=4;
```

## 1.7主从备份

### 1.7.1主从备份原理

主从复制是指一台服务器充当主数据库服务器，另一台或多台服务器充当从数据库服务器，主服务器中的数据自动复制到从服务器之中。通过这种手段我们可以做到读写分离，主库写数据，从库读数据，从而提高数据库的可用。
MySQL主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点。

主节点 binary log dump 线程：
当从节点连接主节点时，主节点会创建一个`log dump` 线程，用于发送`binlog`的内容。在读取`binlog`中的操作时，此线程会对主节点上的`binlog`加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。

 从节点I/O线程:
 用于从库将主库的`binlog`复制到本地的`relay log`中，首先，从库库会先启动一个工作线程，称为IO工作线程，负责和主库建立一个普通的客户端连接。如果该进程追赶上了主库，它将进入睡眠状态，直到主库有新的事件产生通知它，他才会被唤醒，将接收到的事件记录到`relay log`(中继日志)中。
 
 从节点SQL线程:
 SQL线程负责读取`relay log`中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。
 
 ### 1.7.2 主从备份延迟
主备延迟最直接的表现是，备库消费中继日志（`relay log`）的速度，比主库生产`binlog` 的速度要慢。可能导致的原因有：
- 大事务，主库上必须等事务执行完成才会写入binlog，再传给备库，当一个事物用时很久的时候，在从库上会因为这个事物的执行产生延迟。
- 从库压力大。

主备延迟当然是不好的，那么有哪些办法尽量减小主备延迟呢？有下面几个办法：
- 一主多从——多接几个从库，让这些从库来分担读的压力。这样方法适用于从库读压力大的时候。
- 通过binlog输出到外部系统，比如Hadoop这类系统，让外部系统提供统计类查询的能力

### 1.7.3 主从备份配置
主机：
```shell

vi /etc/my.cnf


#主数据库端ID号
server_id = 1           
 #开启二进制日志                  
log-bin = mysql-bin    
#需要复制的数据库名，如果复制多个数据库，重复设置这个选项即可                  
binlog-do-db = db        
#将从服务器从主服务器收到的更新记入到从服务器自己的二进制日志文件中                 
log-slave-updates                        
#控制binlog的写入频率。每执行多少次事务写入一次(这个参数性能消耗很大，但可减小MySQL崩溃造成的损失) 
sync_binlog = 1                    
#这个参数一般用在主主同步中，用来错开自增值, 防止键值冲突
auto_increment_offset = 1           
#这个参数一般用在主主同步中，用来错开自增值, 防止键值冲突
auto_increment_increment = 1            
#二进制日志自动删除的天数，默认值为0,表示“没有自动删除”，启动时和二进制日志循环时可能删除  
expire_logs_days = 7                    
#将函数复制到slave  
log_bin_trust_function_creators = 1       
```

登录mysql
```sql
#创建slave账号account，密码123456
mysql>grant replication slave on *.* to 'account'@'10.10.20.116' identified by '123456';
#更新数据库权限
mysql>flush privileges;

# 检查log-bin
show variables like ‘log_bin’

#查看主服务器状态
show master status\G;


```

从机：
```shell
vi /etc/my.cnf


server_id = 2
log-bin = mysql-bin
log-slave-updates
sync_binlog = 0
#log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下在事务提交的时候，不会主动触发写入磁盘的操作
innodb_flush_log_at_trx_commit = 0        
#指定slave要复制哪个库
replicate-do-db = db         
#MySQL主从复制的时候，当Master和Slave之间的网络中断，但是Master和Slave无法察觉的情况下（比如防火墙或者路由问题）。Slave会等待slave_net_timeout设置的秒数后，才能认为网络出现故障，然后才会重连并且追赶这段时间主库的数据
slave-net-timeout = 60                    
log_bin_trust_function_creators = 1

```
登录mysql
```sql
#执行同步命令，设置主服务器ip，同步账号密码，同步位置
mysql>change master to master_host='10.10.20.111',master_user='account',master_password='123456',master_log_file='mysql-bin.000033',master_log_pos=337523;
#开启同步功能
mysql>start slave;
#查看从服务器状态
mysql>show slave status\G;
```


## 1.8 分布式事务
由于篇幅问题，这里不再对分布式事物的概念做普及，直接介绍两种分布式事务: XA 分布式事务和 TCC分布式事务。

### 1.8.1 XA分布式事务

XA是两阶段提交的强一致性事物。在MySQL 5.7.7版本中，Oracle 官方将MySQL XA 一直存在的一个“bug” 进行了修复，使得MySQL XA 的实现符合了分布式事务的标准。

XA事务中的角色：
- 资源管理器（resource manager）：用来管理系统资源，是通向事务资源的途径。数据库就是一种资源管理器。资源管理还应该具有管理事务提交或回滚的能力。
- 事务管理器（transaction manager）：事务管理器是分布式事务的核心管理者。事务管理器与每个资源管理器（resource 
manager）进行通信，协调并完成事务的处理。事务的各个分支由唯一命名进行标识。

XA规范的基础是两阶段提交协议：

在第一阶段，交易中间件请求所有相关数据库准备提交（预提交）各自的事务分支，以确认是否所有相关数据库都可以提交各自的事务分支。当某一数据库收到预提交后，如果可以提交属于自己的事务分支，则将自己在该事务分支中所做的操作固定记录下来，并给交易中间件一个同意提交的应答，此时数据库将不能再在该事务分支中加入任何操作，但此时数据库并没有真正提交该事务，数据库对共享资源的操作还未释放（处于锁定状态）。如果由于某种原因数据库无法提交属于自己的事务分支，它将回滚自己的所有操作，释放对共享资源上的锁，并返回给交易中间件失败应答。

在第二阶段，交易中间件审查所有数据库返回的预提交结果，如所有数据库都可以提交，交易中间件将要求所有数据库做正式提交，这样该全局事务被提交。而如果有任一数据库预提交返回失败，交易中间件将要求所有其它数据库回滚其操作，这样该全局事务被回滚。

mysql允许多个数据库实例参与一个全局的事务。MySQL XA 的命令集合如下：
```sql
-- 开启一个事务，并将事务置于ACTIVE状态，此后执行的SQL语句都将置于该是事务中。

XA START xid
-- 将事务置于IDLE状态，表示事务内的SQL操作完成。
XA END xid

-- 事务提交的准备动作，事务状态置于PREPARED状态。事务如果无法完成提交前的准备操作，该语句会执行失败。
XA PREPARE xid

-- 事务最终提交，完成持久化。
XA COMMIT xid

-- 事务回滚终止
XA ROLLBACK xid

-- 查看MySQL中存在的PREPARED状态的xa事务。
XA RECOVER
```
MySQL 在XA事务中扮演的是参与者的角色，被事务协调器所支配。XA事务比普通本地事务多了一个`PREPARE`状态，普通事务是 begin-> commit 而分布式事务是 begin->PREPARE 等其他数据库事务都到PREPARE状态的时候再 PREPARE->commit。分布式事务sql示例：

```sql
 xa start 'aaa';
 insert into table(xxx) values(xxx);
 xa end 'aaa';
 xa prepare 'aaa';
 xa commit 'aaa';
```
XA事务存在的问题：

- 单点问题:事务管理器在整个流程中扮演的角色很关键，如果其宕机，比如在第一阶段已经完成，在第二阶段正准备提交的时候事务管理器宕机，资源管理器就会一直阻塞，导致数据库无法使用。
- 同步阻塞:在准备就绪之后，资源管理器中的资源一直处于阻塞状态，直到提交完成才能释放资源。
- 数据不一致:两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务commit的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。


### 1.8.2 TCC分布式事务
TCC又被称作柔性事务，通过事务补偿机制来达到事务的最终一致性，它不是强一致性的事务。TCC将事务分为两个阶段，或者说是由两个事务组成的。相对于XA事务来说TCC的并发性更好，XA是全局性的事务，而TCC是由两个本地事务组成。

假设我们购买一件商品，后台需要操作两张表——积分表加积分而库存表扣库存，这两张表存在于两个数据库中，使用TCC事务执行这一事务：

1）TCC实现阶段一：Try
在try阶段并不是直接减库存加积分，而是将相关数据改变为预备的状态。库存表先锁定一个库存，锁定的方式可以预留一个锁定字段，当这个字段为一的时候表示这个商品被锁定。积分表加一个数据，这个数据也是被锁定状态，锁定方式和库存表一样。其sql形如：
```sql
update stock set lock=1 where id=1;
insert into credits (lock,...) values (1,...)

```
这两条sql如果都执行成功则进入 Confirm阶段，如果执行不成功则进入Cancel阶段

2）TCC实现阶段二：Confirm

这一阶段正式减库存加积分订单状态改为已支付。执行sql将锁定的库存扣除，为累加积分累加，以及一些其他的逻辑。

3）TCC实现阶段三：Cancel
当try阶段执行不成功，就会执行这一阶段，这个阶段将锁定的库存还原，锁定的积分删除掉。退回到事务执行前的状态。

TCC事务原理很简单，使用起来却不简单。首先TCC事务对系统侵入性很大，其次是让业务逻辑变得复杂。在实际使用中我们必须依赖TCC事务中间件才能让TCC事务得以实现。通常一个TCC事务实现大概是这样子的：某个服务向外暴露了一个服务，这个服务对外正常调用，其他服务并不能感知到TCC事务的存在，而其服务内部，分别实现了Try,Confirm,Cancel三个接口，注册到TCC中间件上去。当调用这个服务的时候，其事务操作由该服务和TCC中间件共同完成。

而TCC事务中间件还要做好其他事情，比如确保Confirm或者Cancel执行成功，如果发现某个服务的Cancel或者Confirm一直没成功，会不停的重试调用他的Cancel或者Confirm逻辑，务必要他成功！即使在尝试多次后无法成功也能通知到系统需要人工排查异常。TCC事务还要考虑一些异常情况的处理，比如说订单服务突然挂了，然后再次重启，TCC分布式事务框架要能够保证之前没执行完的分布式事务继续执行。TCC分布式事务框架还需要做好日志的记录，保存下来分布式事务运行的各个阶段和状态，以便系统上线后能够排查异常，恢复数据。目前开源的TCC事务框架有：`Seata` `ByteTCC` `tcc-transaction` 等。

# 2. javase

## 2.1 集合
关于集合的类图和继承关系这里不再赘述，不懂的请自行百度。这里主要分析的集合类有`Vector`、`TreeSet`、`HashMap`、`HashTable`、`TreeMap`，和`concurrent`包下的并发集合类。

先对集合框架做一个整体上的介绍：

- 顶层接口为`Collection` 和 `Map`,`Collection`的子接口有 `Set`、`list`、`Queue`
- `Collection`的子接口有 `Set`和`list`,Map的实现有 `HashMap TreeMap LinkedHashMap` 等

关于集合我会依次介绍以下几个知识点：泛型、迭代模式、扩容机制、各个集合特点介绍

### 2.1.1泛型
泛型的观念是类型参数化，直白的说就是将类型作为参数来使用，但实际上Java泛型是一种“伪泛型”——它的泛型概念只存在于编译期，在jvm中不存在泛型这种概念，被编译转成机器码后泛型被擦除成原始类型。我们以 `ArrayList` 为例：
```java
public class ArrayList<E> extends AbstractList<E>
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable
{
public boolean add(E e) {
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        elementData[size++] = e;
        return true;
    }
}
```
现在我 new 一个list `List<String> test=new ArrayList<>()` ，`ArrayList` 类编译过后你可以理解成它变成了这样：
```java
public class ArrayList extends AbstractList
        implements List, RandomAccess, Cloneable, java.io.Serializable
{
public boolean add(Object e) {
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        elementData[size++] = e;
        return true;
    }
}
```
相当于泛型只起到占位符的作用和给编译器检查类型的作用，当然这里的实现涉及到了 `泛型擦除` `泛型上下限` `桥接方法` 等的概念。这里控制文章的篇幅就不做介绍，感兴趣的自行百度。这就是伪泛型，在jvm里面它根本不知道有T这个东西。它和真正的泛型比起来是有差异的，在反射机制中提现的尤为明显，这个差异性留给小伙伴们去深入思考。

### 2.1.2 集合迭代器
我们知道遍历集合可以使用它的迭代器，这里的设计模式就是迭代器模式，我们对它的迭代器模式进行简单的分析。以Arraylist为例，在AarrayList里面有个内部类，它长这样：
```java
 private class Itr implements Iterator<E> {
        int cursor;       // index of next element to return
        int lastRet = -1; // index of last element returned; -1 if no such
        int expectedModCount = modCount;

        Itr() {}
        ......
}
```
这个就是它的迭代器， Itr 内部定义了三个 int 型的变量：cursor、lastRet、expectedModCount；

- cursor 表示下一个元素的索引位置，lastRet 表示上一个元素的索引位置；

- modCount 用于记录 ArrayList 集合的修改次数；

- expectedModCount预期被修改的次数；

### 2.1.3 扩容

java8以前的扩容机制和java8的扩容

### 2.1.4各个集合的简单介绍
hashmap的优化 vector并不安全 并发包下的集合原理。

## 2.3 nio

## 2.4 java8 新特性

## 2.5 其他


# 3 jvm

## 3.1 运行时数据区域

 &emsp; &emsp;想要了解jvm，那对其内存分配管理的学习是必不可少的；java虚拟机在执行java程序的时候会把它所管理的内存划分成若干数据区域。这些区域有着不同的功能、用途、创建/销毁时间。java虚拟机所分配管理的内存区域如图1所示

### 3.1.1 程序计数器

&emsp; &emsp;程序计数器是一块比较小的内存空间，它可以看做是当前线程所执行的字节码的执行位置的指针。在虚拟机中字节码，解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的指令；虚拟机完成分支、循环、跳转、异常处理、线程恢复等功能都需要依靠它。
&emsp; &emsp;我们知道jvm多线程是通过线程的轮流切换并分配处理器执行时间的的方式来实现的，在任何时刻，一个处理器都只会执行一条线程中的指令。为了使线程被切换后能恢复到正确的执行位置，每条线程的程序计数器都应该是独立的，各条线程之间的计数器互不干涉，独立存储————程序计数器的内存区域为线程私有的内存。<br/>
&emsp; &emsp;如果线程正在执行的是java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果执行的是Native方法，这个计数器的值则为空。此内存区域是唯一一个在jvm规范中没有规定任何OutOfMemoryerror情况的区域


### 3.1.2 java虚拟机栈

&emsp; &emsp;java虚拟机栈为线程私有的内存，其生命周期与线程相同。每个方法在执行的时候会创建一个栈帧用于存储局部变量表、操作数栈、方法出口等信息。每一个方法从调用到执行完成，就对应着一个栈帧在虚拟机中从入栈到出栈的过程。其局部变量表存放了方法编译期可知的各种基本数据类型、对象引用、returnAddress类型（指向一条字节码指令的地址）jvm规范中，这个区域规定了两种异常状况：StackOverflowError和OutOfMemoryError。

### 3.1.3 本地方法栈

&emsp; &emsp;本地方法栈的作用和虚拟机栈的作用很相似，它们的区别在于虚拟机栈为虚拟机执行java方法服务，而本地方法栈则为执行本地方法服务。有的虚拟机直接把本地方法栈和虚拟机栈二合一。与虚拟机栈一样，本地方法栈的异常也有两个：StackOverflowError和OutOfMemoryError。

### 3.1.4 java堆区

&emsp; &emsp;java堆是虚拟机所管理的内存中最大的一块，它是被所有线程共享的一块内存区域，该区域在虚拟机启动的时候创建。这个区域的唯一目的就是存放对象实例。java堆是垃圾收集器工作的主要区域，由于垃圾收集器基本都采用分代收集的算法，所以java堆从垃圾收集器的角度来划分可以细分为新生代和老年代；从内存分配的角度来看，线程共享的java堆可能划分出多个线程私有的分配缓冲区。<br/>
&emsp; &emsp;java堆区可以是物理上不连续的内存空间，只要逻辑上是连续的即可；一般而言我们的虚拟机java堆内存不是固定大小的，是可以扩展的。如果在堆中没有足够内存分配给对象实例，并且堆内存无法再扩展时，虚拟机将会抛出OutOfMemoryError异常。

### 3.1.5 方法区

&emsp; &emsp;方法区与java堆区一样是各个线程共享的内存区域，这个区域存储了类信息、常量、静态变量等数据。java虚拟机规范中把方法区描述为堆得一部分逻辑，它又有一个名字——非堆，目的是与普通java堆进行区分。相对而言垃圾收集器在这个区域很少活动，因此一部分人把这个区域叫做“永久代”。这个区域的内存回收目标主要是针对常量池的回收和类型的卸载，然而类型卸载的条件是很苛刻的。该区域和和java堆区一样，当内存不够分配时会抛出OutOfMemoryError.

### 3.1.6 运行时常量池

&emsp; &emsp;运行时常量池是方法区的一部分；一个Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是编译时常量池，用于存放编译期生成的常量。编译时常量池在类被加载后会放入方法区的运行时常量池中。与编译期常量池不同的是，运运行时常量池是动态的，运行期间产生的新的常量也会被放入这个区域，如：String类的intern()方法。

## 3.2 对象

### 3.2.1 对象的创建

&emsp; &emsp;在语言层面上，创建一个对象通常是通过new关键字来创建，在虚拟机中遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过；如果没有的话就会先加载这个类；类加载检查完后，虚拟机将会为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，在堆中为对象划分一块内存出来。

&emsp; &emsp;虚拟机给对象分配内存的方式有两种——“指针碰撞”的方式和“空闲列表”的方式。如果java堆内存是绝对规整的，所有用过的内存放在一边，未使用的内存放在另一边，中间放一个指针作为指示器，那分配内存就只是把指针向未使用区域挪一段与对象大小相等的距离；这种分配方式叫指针碰撞式，如图1所示。

**图中水印是我以前公众号的名字，并非盗图（现改名为六个核弹）**

![图1：指针碰撞式内存分配方式](http://upload-images.jianshu.io/upload_images/13612520-35177fc9f287a7f3?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们知道，堆内存随时都可能被垃圾收集器回收的，当内存被回收后堆内存就可能不是连续的了，所以当采用指针碰撞的方式时，垃圾收集器必须有内存整理的功能，能对垃圾回收后的零散内存进行整理。而空闲列表的方式则不需要垃圾收集有这个功能，采用这种方式时虚拟机会维护一张表，用于记录那些内存是可用的，当需要分配内存时就从表中找出一块足够的内存进行分配，并记录在表上。

&emsp; &emsp;内存分配完成后，虚拟机需要将分配到的内存空间都初始化；接下来虚拟机会对对象进行必要的设置，例如这个对象是哪个类的实例，如何才能找到类的元数据信息、对象的哈希值、对象的GC的分代年龄等信息。这些信息存在对象的对象头之中。完成这些工作后，从虚拟机的角度来看一个新的对象就产生了，但从程序的角度来看对象创建才刚刚开始，对象尚未执行初始化方法，各个字段都还未赋值，接下来会执行初始化方法，只有在执行初始化方法后，一个真正可用的对象才算是被创建。

### 3.2.2 对象的内存

在HotSpot虚拟机中，对象在内存中分为三块区域：对象头、实例数据、和对齐填充。对象头包括两部分信息，第一部分用于存储对象自身运行的运行时数据，如哈希码、GC分代年龄、锁状态标志线程持有的锁等。对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例
。接下来的实例数据部分是对象真正存储的有效信息，也是在代码中所定义的各个字段的内容。这些字段无论是在父类那继承过来的还是子类里定义都要记录下来。第三部分对齐填充不是必然存在的，它仅仅起占位符的作用，用以填充内存。

### 3.2.3 对象的访问定位

  &emsp; &emsp;建立对象是为了使用对象，我们的java程序需要通过栈上的reference来操作堆上的对象。通过reference来访问对象的方法有两种——使用句柄和直接指针。在虚拟机执行一个方法时，虚拟机栈 中会为方法分配一个 局部变量表，一个操作数栈；局部变量表是用于保存函数的参数以及局部变量的，其保存的类型有boolean、byte、char、short、int、float、reference和returnAddress八种；方法在执行的过程中，会有各种各样的字节码指令往操作数栈中执行入栈和出栈操作，完成数据的运算。基本数据类型直接存储到变量表中。那reference是如何找到引用的对象的呢？

  &emsp; &emsp;如果使用句柄的话，那么会在java堆中划分一块内存来作为句柄池，reference中存储的是句柄的地址，而句柄中包含了对象的具体地址信息，如图2所示
![图:2：通过句柄访问对象](http://upload-images.jianshu.io/upload_images/13612520-444340fc1999cdc6?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  &emsp; &emsp;如果使用直接指针访问，那么java堆对象的布局则如图3所示；
![图3：通过直接指针访问对象](http://upload-images.jianshu.io/upload_images/13612520-cfd7ee35d69ee849?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


## 3.3 垃圾收集器

&emsp; &emsp;java内存在运行时被分为多个区域，其中程序计数器、虚拟机栈、本地方法栈三个区域随线程生成和销毁；每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，在这几个区域内就不需要过多考虑回收问题，因为方法结束或者线程结束时，内存自然就跟着回收了。而堆区就不一样了，我们只有在程序运行的时候才能知道哪些对象会被创建，这部分内存是动态分配的，垃圾收集器主要关注的也就是这部分内存。

### 3.3.1 垃圾收集器算法

&emsp; &emsp;jdk11刚发布不久，这个版本发布了一款新的垃圾收集器——G1垃圾收集器,这款垃圾收集器有很多优异的特性，我会在后文做介绍，这里先从简单的慢慢说起。

&emsp; &emsp;引用计数算法是最初垃圾收集器采用的算法，也是相对简单的一种算法，其原理是：给对象中添加一个引用计数器，每当有一个地方引用它的时候这个计数器就加一；当引用失效，计数器就减一；任何时刻计数器为0则该对象就会被垃圾收集器回收。这种算法的缺点是当对象之间相互循环引用的时候，对象将永远不会被回收。举个例子——有类TestOne,类TestTwo;它们互相是对方的成员，如下：

```java
 public static void main(String[] args) {
    TestOne testOne=new TestOne();
    TestTwo testTwo=new TestTwo();
    testOne.obj=testTwo;
    testTwo.obj=testOne;
    testOne=null;
    testTwo=null;
}

```

理论上当代码执行到testTwo=null的时候 new TestOne() new TestTwo() 两块内存应该要被回收的，但是因为它们相互引用对方导致引用计数器不为0，所以这两块内存没有引用指向它们却无法被回收——这便是这种算法所存在的问题。

&emsp; &emsp;可达性分析算法是使用比较广泛的算法。这个算法的基本思路是通过一系列的称为“GC Roots”的对象作为起点，从这些节点向下搜索，搜索所走过的路径称作引用链；当一个对象和GC Roots之间不存在引用链的时候，这个对象将被回收；也就是说一个存活的对象向上追溯它的引用链，其头部必然是GC Roots,如果不是将被回收。在虚拟机中可以作为GC Roots的可以是：虚拟机栈中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象，本地方法栈中Native方法引用的对象；在堆区一个存活的对象被这些对象所直接引用或间接引用(引用又分为强引用、软引用、弱引用、、虚引用，引用强调依次降低，感兴趣的可以详细了解一下)。
&emsp; &emsp;当一个对象的引用链中没有GC Roots的时候并不会被马上回收，第一次他会被标记并筛选，当对象没有覆盖finalize()方法或该方法已经被虚拟机调用过，那么它会被放入一个叫做F-Queue的队列中等待被虚拟机自动回收；否则虚拟机会执行finalize()方法——当我们没有重写finalize()方法时，对象内存自然被回收掉，如果重写了这个方法，那么结果就会变得很有趣，下面做一个示例：

```java
public class Main {
    public static  Main test=null;

    @Override
    protected void finalize() throws Throwable {
        super.finalize();
        System.out.println("执行了一次 finalize()");
        Main.test=this;
    }

    public static void main(String[] args) {
        test=new Main();
        // 让test失去 GC RootS
        test=null;
        // 调用 finalize()方法
        System.gc();
        // sleep一会确保finalize()方法执行
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 因为在finalize()方法中重新将this(也就是 new Main())赋值给了test 所以没被回收
        if(test!=null){
            System.out.println("对象存活了下来");
        }else{
            System.out.println("对象死了");
        }
        // 再来一次
        test=null;
        System.gc();
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 这一次却死了，因为finalize()方法已经被执行过，虚拟机直接将对象扔到 F-Queue里面等待回收
        if(test!=null){
            System.out.println("对象存活了下来");
        }else{
            System.out.println("对象死了");
        }
    }

}
```

运行结果：

> 执行了一次 finalize()<br/>
> 对象存活了下来<br/>
> 对象死了

### 3.3.2 回收方法区

&emsp; &emsp;因为方法区的内存回收条件很苛刻，因此方法区被人称作永久代，在这个区域回收的内存主要为废弃的常量和无用的类；那么如何判定一个常量是否废弃呢？比如当一个字符串进入了常量池，但没有任何地方引用它，如果此时发生了内存回收，那么这个常量就会被清除出常量池——发生场景：一个类有一个成员 pubulic static String test="aaa";当这个类被加载的时候"aaa"进入常量池，当其他地方没有字符串等于"aaa"的时候并且此时这个类由于某种原因被卸载掉，此时这个"aaa"将会被回收。如何判定一个类是无用的类呢？需要满足三个条件：

> 该类所有的实例都被回收<br/>
> 加载该类的ClassLoader已经被回收
> <br/>该类的Class对象没在任何地方被引用，无法通过反射访问该类

### 3.3.3 分代收集



## 3.4 垃圾收集算法

### 3.4.1 标记-清除算法

标记-清除算法是最基础的算法，算法分为标记和清除两个阶段，首先标记出要清除的对象，在标记完后统一回收所有被标记的对象，标记方式为j《jvm系列之垃圾收集器》里面所提到的。这种算法标记和清除两个过程效率都不高；并且在标记清除后，内存空间变得很零散，产生大量内存碎片。当需要分配一个比较大的对象时有可能会导致找不到足够大的内存。<!--more-->

标记清除算法图解（图片来源于百度图片）：![timg.jpg](https://upload-images.jianshu.io/upload_images/13612520-e59da44ca1b963c6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 

### 3.4.2 清除-复制算法

&emsp;为了解决标记清除效率低的问题，出现了复制算法；这种算法将内存划分为大小相等的两块内存，只使用其中一块。当这一块内存使用完了就将存活的对象复制到另一块上面去，然后把已使用的内存空间一次性清理掉，这种方法不必考虑内存碎片的情况，运行高效，实现简单。缺点是浪费了一半的内存。复制算法图解（图片来源百度图片）：![timg (1).jpg](https://upload-images.jianshu.io/upload_images/13612520-2f12466c88adfd82.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 3.4.3 标记-整理算法

&emsp; &emsp;复制收集算法在对象存活率较高的时候就要进行较多的复制操作，导致效率变低。而且老年代很少会有内存回收，对老年代而言，复制算法做了大量的无用功。针对复制算法存在的的问题，有人提出了标记-整理算法。标记过程和标记-清除算法过程一样，但后续不是直接对可回收对象进行清理，而是让所有存活对象都向一方移动，整理内存，然后再进行清理。标记-整理算法图解（图片来源百度图片）：![timg (2).jpg](https://upload-images.jianshu.io/upload_images/13612520-4fd6dd6461485a3c.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 3.4.4 分代收集算法

&emsp; &emsp;分代收集算法思路是根据对象存活周期不同将内存划分为几块。一般是分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中每次收集时都会回收很多内存，选用高效率的复制算法，并且只需要预留少量的复制空间，用于复制存活对象。老年代中因为对象存活率高，采用标记-整理或标记清理算法节省内存空间提高清理效率。

### 3.4.5 各版本jdk垃圾收集器一览

| 收集器名称        | 区 &emsp; 域  | 说明  &emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp; |
| ----------------- | :-----------: | -----------------------------------------------------------: |
| Serial            |    新生代     | 单线程，GC时必须停止其它线程直到收集结束；JVM运行在client模式下新生代的默认收集器，简单有效；采用复制算法 |
| ParNew            |    新生代     | Serial收集的多线程版，保留Serial的参数控制，算法等，暂停所有用户线程，采用复制算法；JVM运行在server的首先的新生代收集器；只有它能和CMS配合工作 |
| Parallel Scavenge |    新生代     | 采用复制算法，并行的多线程收集器，与ParNew不同的是，关注点不是停顿时间，而是可控制的吞吐量，即运行用户代码的时间/（运行用户代码的时间+垃圾收集的时间）。可设置最大GC时间和吞吐量大小等参数，也可以让JVM自适应调整策略 |
| CMS               |    新生代     | concurrent Mark Sweep，已获取最短回收停顿为目标，大部分的互联网站及服务端采用的方式，标记-清除算法 |
| G1                | 新生代/老年代 |                   收集器最前沿版本，JDK 1.7，代替CMS的新产品 |
| Serial Old（MSC） |    老年代     | Serial的老年版，单线程收集器，采用标记-整理算法，主要是client模式的JVM使用 |
| Parallel Old      |    老年代     |              Parallel Scavenge的老年版，多线程，标记整理算法 |

### 3.4.6 jdk11 垃圾收集器——ZGC

&emsp; &emsp;（网上搜的）ZGC是一个处于实验阶段的，可扩展的低延迟垃圾回收器，旨在实现以下几个目标：

- 停顿时间不超过10ms
- 停顿时间不随heap大小或存活对象大小增大而增大
- 可以处理从几百兆到几T的内存大小

限制：

- 当前版本不支持类卸载
- 当前版本不支持JVMCI

ZGC包含10个阶段，但是主要是两个阶段标记和relocating。GC循环从标记阶段开始，递归标记所有可达对象，标记阶段结束时，ZGC可以知道哪些对象仍然存在哪些是垃圾。ZGC将结果存储在每一页的位图（称为live map）中。在标记阶段，应用线程中的load barrier将未标记的引用压入线程本地的标记缓冲区。一旦缓冲区满，GC线程会拿到缓冲区的所有权，并且递归遍历此缓冲区所有可达对象。注意：应用线程负责压入缓冲区，GC线程负责递归遍历。

&emsp; &emsp;标记阶段后，ZGC需要迁移relocate集中的所有对象。relocate集是一组页面集合，包含了根据某些标准（例如那些包含最多垃圾对象的页面）确定的需要迁移的页面。对象由GC线程或者应用线程迁移（通过load barrier）。ZGC为每个relocate集中的页面分配了转发表。转发表是一个哈希映射，它存储一个对象已被迁移到的地址（如果该对象已经被迁移）。GC线程遍历relocate集的活动对象，并迁移尚未迁移的所有对象。有时候会发生应用线程和GC线程同时试图迁移同一个对象，在这种情况下，ZGC使用CAS操作来确定胜利者。一旦GC线程完成了relocate集的处理，迁移阶段就完成了。虽然这时所有对象都已迁移，但是旧地引用址仍然有可能被使用，仍然需要通过转发表重新映射（remapping）。然后通过load barrier或者等到下一个标记循环修复这些引用。


## 3.5 类加载机制

### 3.5.1 类的生命周期

&emsp; &emsp;类从被加载到虚拟机内存中内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（loading）、验证（verification）、准备（preparation）、解析（resolution）、初始化（initialization）、使用（using）卸载（unloading）七个阶段。其中验证、准备、解析三个阶段统称为连接（linking）。

<!--more-->

### 3.5.2 加载

&emsp; &emsp;加载是类加载机制的第一个阶段，在这个阶段，虚拟机做了三件事情：

> - 通过类的全限定名来获取定义此类的二进制字节流；

- 将这个字节流所代表的静态存储结构转换为方法区的运行时数据结构
- 在内存中生成一个代表这个类的Class对象，作为方法区这个类的各种数据的访问入口

&emsp; &emsp;加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，方法区中的数据存储格式由虚拟机实现自行定义；然后在内存中实例化一个Class类的对象，加载阶段和连接阶段的部分内容是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始了。

### 3.5.3 验证

&emsp; &emsp;验证是连接阶段的第一步，这一阶段目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。从整体上来看，验证阶段包括以下四个动作：文件格式验证、元数据验证、字节码验证、符号引用验证。

### 3.5.4 准备

&emsp; &emsp;准备阶段是正式为类变量分配内存并设置类变量初始值得阶段，这些变量所使用的内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的概念——1.这个时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，2.这里初始值是数据类型的零值，假设一个类变量定义为 ：

```java
public static int value=2;
```

那变量value在准备阶段的值为0而不是2.

### 3.5.5 解析

&emsp; &emsp;解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。

### 3.5.6 初始化

&emsp; &emsp;类初始化阶段是类加载过程的最后一步，前面的类加载过程中，除了在加载阶段可以通过自定义类加载器参与之外，其余动作都是虚拟机控制的。到了初始化阶段，才真正的执行java代码。初始化阶段是执行类构造器<clinit>()方法的过程。

&emsp; &emsp;想要使用一个类，必须对其进行初始化，但初始化过程不是必然执行的；jvm规范中规定有且只有以下五种情况必须对类进行初始化：

> - 遇到new、getstatic、putstatic、invokestatic这四个字节码指令的时候，如果类没有进行初始化，则需要先触发其初始化。生成这四条指令最常见的java代码场景是：使用new创建对象、读取或者设置一个类的静态字段（不包括值已在常量池中的情况）、调用一个类的静态方法的时候；

- 使用java反射机制的时候，如果类没初始化需要先初始化；
- 当初始化一个类的时候，如果发现其父类还未初始化，则需要先初始化父类。
- 当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先初始化那个类。

以上五种情况称为对一个类进行主动引用；其他引用类的方式都不会触发初始化，称为被动引用。下面举一个被动引用的例子：

```java
public class TestClassloading {
    static {
        System.out.println("父类被初始化");
    }
    public static int number=111;
}

public class SubClass extends TestClassloading {
    static {
        System.out.println("子类被初始化");
    }
}

public class Main {
    public static void main(String[] args) {
        System.out.println(SubClass.number);
    }
}
```

输出结果：

```java
父类被初始化
111
```

显然，子类没有被初始化，这里SubClass.number为被动引用，不会对子类初始化。

### 3.5.7 类加载器

&emsp; &emsp;通过一个类的全限定名来获取描述此类的二进制字节流这个动作被放到虚拟机外部区实现，以便让应用程序自己决定如何去获取所需的类，实现这个动作的代码模块称为类加载器。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在java虚拟机中的唯一性，每一个类加载器都拥有一个独立的类名称空间。也就是说比较两个类是否相等必须要类加载器和类都相等。
&emsp; &emsp;从java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器，这个类加载器是虚拟机的一部分；另一种就是java代码实现的独立于虚拟机外部的类加载器，这种类加载器继承类抽象类java.lang.TestClassloader。

&emsp; &emsp;类加载器还有一个很重要的概念就是双亲委派模型——在类加载器工作的时候是多个类加载器一起工作的它们包括：扩展类加载器，应用程序类加载器，启动类加载器，自定义类加载器。类加载器的层次图如图：

![](https://upload-images.jianshu.io/upload_images/13612520-dd9a6a8324f136f8?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

类加载器层次结构

&emsp; &emsp;双亲委派模型的工作流程是如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求交给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都会被交给启动类加载器，当父类反馈无法加载这个类的时候，子类才会进行加载。

Java的类加载机制：
- BootstrapClassLoader负责加载${JAVA_HOME}/jre/lib部分jar包
- ExtClassLoader加载${JAVA_HOME}/jre/lib/ext下面的jar包
- AppClassLoader加载用户自定义-classpath或者Jar包的Class-Path定义的第三方包

`BootstrapClassLoader` 为C语言编写的加载器，它会负责加载包括 `ExtClassLoader` 和 `AppClassLoader` 等的 `java.*` 和 `sun.*` 包下的类。而 `ExtClassLoader` 和 `AppClassLoader` 在内的类加载器， 实质性的类加载也需要依托于 `JNI` 机制

## 3.6 引用类型

在JDK 1.2以前的版本中，若一个对象不被任何变量引用，那么程序就无法再使用这个对象。对象引用被划分成简单的两种状态：可用和不可用。从JDK 1.2版本以后，对象的引用被划分为`4`种级别，从而使程序能更加灵活地控制对象的生命周期，引用的强度由高到低为：强、软、弱、虚引用。

对象生命周期：在JVM运行空间中，对象的整个生命周期大致可以分为7个阶段：创建阶段（Creation）、应用阶段（Using）、不可视阶段（Invisible）、不可到达阶段（Unreachable）、可收集阶段（Collected）、终结阶段（Finalized）与释放阶段（Free）。上面的这7个阶段，构成了 JVM中对象的完整的生命周期。

### 3.6.1 强引用(StrongReference)

强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它，我们使用new关键字就是创建了一个强引用。被强引用引用的内存是无法被GC回收的，想要回收这一块的内存得等这个引用从栈内存中出来，对应的内存无引用了才能被回收。

### 3.6.2 软引用(SoftReference)

如果一个对象只具有软引用，则内存空间充足时，GC不会回收这块内存；单如果内存不足的时候它就会被回收，只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。

创建一个软引用的办法

```java
    String str = new String("xxx");
    SoftReference<String> softReference = new SoftReference<String>(str);
```

`softReference`就是一个软引用。

当内存不足时，`JVM`首先将软引用中的对象引用置为`null`，然后通知垃圾回收器进行回收。也就是说当软引用指向null的时候，对应的内存可能还是未被GC回收的。虚拟机会尽可能的优先回收长时间闲置不用的软引用对象。

### 3.6.3 弱引用(WeakReference)

弱引用比软引用有更短暂的生命周期。在GC扫描内存区域的时候，一旦发现弱引用就会马上回收它。

创建一个弱引用的方法：

```java
String str = new String("xxx");
WeakReference<String> weakReference = new WeakReference<>(str);
// 弱引用转强引用
String strongReference = weakReference.get();
```

如果一个对象是偶尔(很少)的使用，并且希望在使用时随时就能获取到，但又不想影响此对象的垃圾收集，那么你应该用Weak Reference来记住此对象。如上面代码所示，弱引用也也可以转换成强引用

### 3.6.4 虚引用(PhantomReference)

虚引用可以理解为形同虚设的引用，不管你这个引用指向的内存有没有在用，它都随时可能被回收掉。虚引用必须和引用队列(ReferenceQueue)联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。

创建虚引用的办法：

```java
 String str = new String("xxx");
ReferenceQueue queue = new ReferenceQueue();
// 创建虚引用，要求必须与一个引用队列关联
PhantomReference pr = new PhantomReference(str, queue);
```

虚引用基本上好像没啥卵用。

GC线程在虚拟机中的优先级别很低的，因此占用cpu资源的机会很少，所以当一个内存变成非强引用的时候，不一定马上会被回收，而是看这个时候GC线程有没有在执行。如果GC在执行，它会先检查这个内存有没有有引用指向它，如果没有就回收，如果有那么根据引用的级别来采用垃圾回收策略。



# 4. 并发

## 4.1 基本概念

### 4.1.1同步和异步

同步和异步通常来形容一次方法的调用。同步方法一旦开始，调用者必须等到方法结束才能执行后续动作；异步方法则是在调用该方法后不必等到该方法执行完就能执行后面的代码，该方法会在另一个线程异步执行，异步方法总是伴随着回调，通过回调来获得异步方法的执行结果；

### 4.1.2 并发和并行

很多人都将并发与并行混淆在一起，它们虽然都可以表示两个或者多个任务一起执行，但执行过程上是有区别的。并发是多个任务交替执行，多任务之间还是串行的；而并行是多个任务同时执行，和并发有本质区别。
对计算机而言，如果系统内只有一个cpu，而使用多进程或者多线程执行任务，那么这种情况下多线程或者多进程就是并行执行，并行只可能出现在多核系统中。当然，对java程序而言，我们不必去关心程序是并行还是并发。

### 4.1.3 临界区

临界区表示的是多个线程共享但同时只能有一个线程使用它的资源。在并行程序中临界区资源是受保护的，必须确保同一时刻只有一个线程能使用它。

### 4.1.4 阻塞

如果一个线程占有了临界区的资源，其他需要使用这个临界区资源的线程必须在这个临界区进行等待——线程被挂起，这种情况就是发生了阻塞——线程停滞不前。

### 4.1.5 死锁\饥饿\活锁

死锁就是多个线程需要其他线程的资源才能释放它所拥有的资源，而其他线程释放这个线程需要的资源必须先获得这个线程所拥有的资源，这样造成了矛盾无法解开；如图1情形就是发生死锁现象：

![](http://a2.qpic.cn/psb?/V13ysUCU2bV4he/zBrKU1zKzRRphjYm8*58YnBjOH0x7EvRxnWkrr.0oeE!/b/dMEAAAAAAAAA&ek=1&kp=1&pt=0&bo=2QENAQAAAAARF*Q!&tl=3&vuin=1793769323&tm=1555678800&sce=60-2-2&rf=viewer_4)

<center>图1：生活中的死锁现象</center>

活锁就是两个线程互相谦让资源，结果就是谁也拿不到资源导致活锁；就好比过马路，行人给车让道，车又给行人让道，结果就是车和行人都停在那不走。

饥饿就是，某个线程优先级特别低老是拿不到资源，导致这个线程一直无法执行

### 4.1.6 并发级别

并发级别分为阻塞，无饥饿，无障碍，无锁，无等待几个级别；根据名字我们也能大概猜出这几个级别对应的什么情形；阻塞，无饥饿和无锁都好理解；我们说一下无障碍和无等待；

无障碍：无障碍级别默认各个线程不会发生冲突，不会互相抢占资源，一旦抢占资源就认为线程发生错误，进行回滚。

无等待：无等待是在无锁上的进一步优化，限制每个线程完成任务的步数；

### 4.1.7 并行的两个定理

加速比：加速比=优化前系统耗时/优化后系统耗时

Amdahl定理： 加速比=1/[F+(1-F)/n] 其中 n表示处理器个数 ，F是程序中只能串行执行的比例——串行率；由公式可知，想要以最小投入，得到最高加速比即 F+(1-F)/n取到最小值，F和n都对结果有很大影响，在深入研究就是数学问题了；

Gustafson定律： 加速比=n-F(n-1)，这两定律区别不大，都体现了单纯的减少串行率，或者单纯的加CPU都无法得到最优解。

## 4.2 Java中的并行基础

### 4.2.3 volatile关键字和程序的原子性，可见性，有序性

原子性指的是一个操作是不可中断的，要么成功要么失败，不会被其他线程所干扰；比如 int=1,这一操作在cpu中分为好几个指令，但对程序而言这几个指令是一体的，只有可能执行成功或者失败，不可能发生只执行了一半的操作；对不同CPU而言保证原子性的的实现方式各有不同，就英特尔CPU而言是使用一个lock指令来保证的。

可见性指某一线程改变某一共享变量，其他线程未必会马上知道。

有序性指对一个操作而言指令是按一定顺序执行的，但编译器为了提高程序执行的速度，会重排程序指令；cpu在执行指令的时候采用的是流水线的形式，上一个指令和下一个指令差一个工步。比如A指令分三个工步：1. 操作内存a，2.操作内存b，3.操作内存c；现假设有个指令B操作流程和A一样，那么先执行指令A在执行指令B时间全利用上了，中间没有停顿等待；但如果有三个这样的指令在流水线上执行：a>b>c，b>e>c，c>e>a；这样的指令顺序就会发生等待降低了CPU的效率，编译器为了避免这种事情发生，会适当优化指令的顺序进行重排。

volatile关键字在java中的作用是保证变量的可见性和防止指令重排。

### 4.2.4 线程的相关操作

*创建线程有三种方法*

- 继承Thread类创建线程
- 实现Runnable接口创建线程
- 使用Callable和Future创建线程

*终止线程的方法*

终止线程可调用stop()方法，但这个方法是被废弃不建议使用的，因为强制终止一个线程会引起数据的不一致问题。比如一个线程数据写到一半被终止了，释放了锁，其他线程拿到锁继续写数据，结果导致数据发生了错误。终止线程比较好的方法是“让程序自己终止”，比如定义一个标识符，当标识符为true的时候直让程序走到终点，这样就能达到“自己终止”的目的。

*线程的中断等待和通知*

interrupt()方法可以中断当前程序，object.wait() 方法让线程进入等待队列，object.notify()随机唤醒等待队列的一个线程， object.notifyAll()唤醒等待队列的所有线程。object.wait()必须在synchronzied语句中调用；执行wait，notify方法必须获得对象的监视器，执行结束后释放监视器供其他线程获取。

*join*

join()方法功能是等待其他线程“加入”，可以理解为将某个线程并为自己的子线程，等子线程走完或者等子线程走规定的时间，主线程才往下走；join的本质是调用调用线程对象的wait方法，当我们执行wait或者notify方法不应该获取线程对象的的监听器，因为可能会影响到其他线程的join。

*yield*

yield是线程的“谦让”机制，可以理解为当线程抢到cpu资源时，放弃这次资源重新抢占，yield()是Thread里的一个静态方法。

### 4.2.5 线程组

如果一个多线程系统线程数量众多而且分工明确，那么可以使用线程组来分类。

```java
	
    @Test
    public void contextLoads() {
        ThreadGroup testGroup=new ThreadGroup("testGroup");
        Thread a = new Thread(testGroup, new MyRunnable(), "a");
        Thread b = new Thread(testGroup, new MyRunnable(), "b");
        a.start();
        b.start();
        int i = testGroup.activeCount();
    }

    public static class MyRunnable implements Runnable{
        @Override
        public void run() {
            System.out.println("test");
        }
    }
```

图示代码创建了一个"testGroup"线程组。

### 4.2.6 守护线程

守护线程是一种特殊线程，它类似java中的异常系统，主要是概念上的分类，与之对应的是用户线程。它功能应该是在后台完成一些系统性的服务；设置一个线程为守护线程应该在线程start之前setDaemon()。

### 4.2.7 线程优先级

java中线程可以有自己的优先级，优先级高的更有优势抢占资源；线程优先级高的不一定能抢占到资源，只是一个概率问题，而对应优先级低的线程可能会发生饥饿；

在java中使用1到10表示线程的优先级，使用setPriority()方法来进行设置，数字越大代表优先级越高；

## 4.3 多线程编程


## java线程锁的分类与实现

以下分类是从多个同角度来划分，而不是以某一标准来划分，请注意

- 阻塞锁：当一个线程获得锁，其他线程就会被阻塞挂起，直到抢占到锁才继续执行，这样会导致CPU切换上下文，切换上下文对CPU而言是很耗费时间的
- 非阻塞锁：当一个线程获得锁，其他线程直接跳过锁资源相关的代码继续执行，就是非阻塞锁
- 自旋锁：当一个线程获得锁，其他线程则在不停进行空循环，直到抢到锁，这样做的好处是避免了上下文切换
- 可重入锁：也叫做递归锁，当一个线程外层函数获得锁之后 ，内层递归函数仍然可以该锁的相关代码，不受影响。
- 互斥锁：互斥锁保证了某一时刻只能有一个线程占有该资源。
- 读写锁：将代码功能分为读和写，读不互斥，写互斥；
- 公平锁/非公平锁：公平锁就是在等待队列里排最前面的的先获得锁，非公平锁就是谁抢到谁用；
- 重量级锁/轻量级锁/偏向锁：使用操作系统“Mutex Lock”功能来实现锁机制的叫重量级锁，因为这种锁成本高；轻量级锁是对重量级锁的优化，提高性能；偏向锁是对轻量级锁的优化，在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径。
- 乐观锁
- 悲观锁

<!--more-->

### synchronized

属于阻塞锁，互斥锁，非公平锁，可重入锁，在JDK1.6以前属于重量级锁，后来做了优化；

用法：

- 指定加锁对象；
- 用于静态代码块/方法
- 用于动态代码块/方法

示例

```
		public static synchronized void test1(){
            System.out.println("test");
        }

        public  synchronized void test2(){
            System.out.println("test");
        }
                 
        public void test3(){
            synchronized (this){
                System.out.println("test");
            }
        }
```

当锁加在静态代码块/方法上时，锁作用于整个类，凡是属于这个类的对象的相关都会被上锁，当用于动态代码块/方法/对象时锁作用于对象；除此之外，synchronized可以保证线程的可见性和有序性。

### Lock

lock 是一个接口，其下有多个实现类；

方法说明：

- lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。
- tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，这个方法还可以设置一个获取锁的等待时长，如果时间内获取不到直接返回。
- 两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程
- unLock()方法是用来释放锁
- newCondition()：生成一个和线程绑定的Condition实例，利用该实例我们可以让线程在合适的时候等待，在特定的时候继续执行；相当于得到这个线程的wait和notify方法；

### ReentrantLock

ReentrantLock重入锁，是实现Lock接口的一个类，它对公平锁和非公平锁都支持；在构造方法中传入一个boolean值，true时为公平锁，false时为非公平锁

### Semaphore(信号量)

信号量是对锁的扩展，锁每次只允许一个线程访问一个资源，而信号量却可以指定多个线程访问某个资源；信号量的构造函数为

```java
public Semaphore(int permits) {
        sync = new NonfairSync(permits);
    }
public Semaphore(int permits, boolean fair) {
        sync = fair ? new FairSync(permits) : new NonfairSync(permits);
    }
```

第一个方法指定了可使用的线程数，第二个方法的布尔值表示是否为公平锁；

acquire()方法尝试获得一个许可，如果获取不到则等待；tryAcquire()方法尝试获取一个许可，成功返回true，失败返回false，不会阻塞，tryAcquire(int i) 指定等待时间；release()方法释放一个许可。

### ReadWriteLock

读写分离锁， 读写分离锁可以有效的减少锁竞争，读锁是共享锁，可以被多个线程同时获取，写锁是互斥只能被一个线程占有，ReadWriteLock是一个接口，其中readLock()获得读锁，writeLock()获得写锁 其实现类ReentrantReadWriteLock是一个可重入得的读写锁，它支持锁的降级(在获得写锁的情况下可以再持有读锁)，不支持锁的升级（在获得读锁的情况下不能再获得写锁）；读锁和写锁也是互斥的，也就是一个资源要么被上了一个写锁，要么被上了多个读锁，不会发生这个资即被上写锁又被上读锁的情况。

### 闭锁和栅栏

### cas
## cas(乐观锁实现)

cas(比较替换)：无锁策略的一种实现方式，过程为获取到变量旧值（每个线程都有一份变量值的副本），和变量目前的新值做比较，如果一样证明变量没被其他线程修改过，这个线程就可以更新这个变量，否则不能更新；通俗的说就是通过不加锁的方式来修改共享资源并同时保证安全性。

使用cas的话对于属性变量不能再用传统的int ,long等；要使用原子类代替原先的数据类型操作，比如AtomicBoolean，AtomicInteger，AtomicInteger等。

### 并发下集合类

并发集合类主要有：

- ConcurrentHashMap：支持多线程的分段哈希表，它通过将整个哈希表分成多段的方式减小锁粒度
- ConcurrentSkipListMap：ConcurrentSkipListMap的底层是通过跳表来实现的。跳表是一个链表，但是通过使用“跳跃式”查找的方式使得插入、读取数据时复杂度变成了O（logn）;
- ConCurrentSkipListSet：参考ConcurrentSkipListMap；
- CopyOnWriteArrayList：是ArrayList 的一个线程安全的变形，其中所有可变操作（添加、设置，等等）都是通过对基础数组进行一次新的复制来实现的; 
- CopyOnWriteArraySet：参考CopyOnWriteArrayList; 
- ConcurrentLinkedQueue：cas实现的非阻塞并发队列;

### 线程池

多线程的设计优点是能很大限度的发挥多核处理器的计算能力，但是，若不控制好线程资源反而会拖累cpu，降低系统性能，这就涉及到了线程的回收复用等一系列问题；而且本身线程的创建和销毁也很耗费资源，因此找到一个合适的方法来提高线程的复用就很必要了。

线程池就是解决这类问题的一个很好的方法：线程池中本身有很多个线程，当需要使用线程的时候拿一个线程出来，当用完则还回去，而不是每次都创建和销毁。在JDK中提供了一套Executor线程池框架，帮助开发人员有效的进行线程控制。

1) Executor使用

获得线程池的方法：

- newFixedThreadPool(int nThreads) ：创建固定数目线程的线程池；
- newCachedThreadPool：创建一个可缓存的线程池，调用execute将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线 程并添加到池中；
- newSingleThreadExecutor：创建一个单线程化的Executor；
- newScheduledThreadPool：创建一个支持定时及周期性的任务执行的线程池。

以上方法都是返回一个ExecutorService对象，executorService.execute()传入一个Runnable对象，可执行一个线程任务

下面看示例代码

```java
public class Test implements Runnable{
	int i=0;
	public Test(int i){
		this.i=i;
	}
	public void run() {
		System.out.println(Thread.currentThread().getName()+"====="+i);
	}
    public static void main(String[] args) throws InterruptedException {
		ExecutorService cachedThreadPool = Executors.newCachedThreadPool();
		for(int i=0;i<10;i++){
			cachedThreadPool.execute(new Test(i));
			Thread.sleep(1000);
		}
	}
}

```

线程池是一个庞大而复杂的体系，本系列文章定位是基础，不对其做更深入的研究，感兴趣的小伙伴可以自行查资料进行

1.1) ScheduledExecutorService

newScheduledThreadPool(int corePoolSize)会返回一个ScheduledExecutorService对象，可以根据时间对线程进行调度；其下有三个执行线程任务的方法：schedule()，scheduleAtFixedRate()，scheduleWithFixedDelay()；该线程池可解决定时任务的问题。

示例：

```java
class Test implements Runnable {
    
    private String testStr;
    
    Test(String testStr) {
        this.testStr = testStr;
    }

    @Override
    public void run() {
        System.out.println(testStr + " >>>> print");
    }
    
    public static void main(String[] args) {
        ScheduledExecutorService service = Executors.newScheduledThreadPool(10);
        long wait = 1;
        long period = 1;
        service.scheduleAtFixedRate(new MyScheduledExecutor("job1"), wait, period, TimeUnit.SECONDS);
        service.scheduleWithFixedDelay(new MyScheduledExecutor("job2"), wait, period, TimeUnit.SECONDS);
        scheduledExecutorService.schedule(new MyScheduledExecutor("job3"), wait, TimeUnit.SECONDS);//延时waits 执行
    }
}
```

job1的执行方式是任务发起后间隔`wait`秒开始执行，每隔`period`秒(注意：不包括上一个线程的执行时间)执行一次；

job2的执行方式是任务发起后间隔`wait`秒开始执行，等线程结束后隔`period`秒开始执行下一个线程；

job3只执行一次，延迟`wait`秒执行；

ScheduledExecutorService还可以配合Callable使用来回调获得线程执行结果，还可以取消队列中的执行任务等操作，这属于比较复杂的用法，我们这里掌握基本的即可，到实际遇到相应的问题时我们在现学现用，节省学习成本。

函数式编程，响应式编程，方法参数化 行为参数化。响应式编程
# 3. netty

## netty类介绍

# 4. redis

## redis结构

# 5. zookeeper
`zookeeper`对分布式系统来说是一个很重要必须要掌握的中间件，对于ZK的安装部署这里就不做介绍了，自行百度，主要讲使用和部分原理。
## 5.1 ZK介绍
`zookeeper`是基于观察者模式设计的分布式服务管理框架，它负责存储和管理比较重要的分布式数据并通知观察者数据的变化状态，直白的说zookeeper是一个数据存储加消息通知系统。zookeeper的应用场景有:

- 统一命名服务：在分布式系统中给每个应用配置一个全局唯一名称，并统一管理
- 统一配置管理：将分布式系统一些配置信息放入到ZK中进行管理
- 统一集群管理：管理监听集群状态
- 服务节点动态上下线：实时通知应用分布式系统中有哪些服务节点。

zk的特性：
- 顺序一致性： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。
- 原子性： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。
- 单一系统映像 ： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。
- 可靠性： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。

## 5.2 ZNode

zookeeper的数据结构整体上一棵树，每个节点被称作`ZNode`，每个ZNode默认存储1MB的数据，每个ZNode 都可以通过路径唯一标识。ZNode共有四种类型：
- 持久节点：指在节点创建后，就一直存在，直到有删除操作来主动清除这个节点。不会因为客户端会话失效而清除；
- 持久顺序节点：在持久节点基础上增加了有序性，其每创建一个子节点都会自动为给节点名加上一个数字后缀作为新的节点名。

- 临时节点：临时节点的生命周期和客户端会话绑定。也就是说，如果客户端会话失效，那么这个节点就会自动被清除掉。
- 临时顺序节点：在临时节点基础上增加了有序性；参考持久顺序节点。

## 5.3 ZK指令
在ZK的安装包中有一个ZK客户端，启动ZK客户端可在其中输入相应的指令来操作ZK，下面对这些指令做简单介绍：

| 指令              | 描述                                                         |
| ----------------- | ------------------------------------------------------------ |
| help              | 显示所有操作命令                                             |
| ls path [watch]   | 查看当前节点内容                                             |
| ls2  path [watch] | 查看当前节点数据并能看到更新次数等数据                       |
| create            | 不带参数创建普通持久节点，-s 创建持久顺序节点 -e 创建临时节点，-s -e 创建 临时顺序节点 |
| get path [wathc]  | 获取节点值                                                   |
| set path          | 给节点赋值                                                   |
| stat path         | 查看节点状态                                                 |
| delete path       | 删除节点                                                     |
| rmr               | 递归删除节点 (参考rm-rf）                                    |
操作示例：
```shell
# 连接zk
./zkCli.sh -server master 2181

# 列出 / 下的节点
ls /

# 创建节点
create /zk-test "123"
create  -s   /zk-test  “test123”
create -e /zk-test123 "test1234"

# 删除节点
delete /zk-test

# 获取节点
get /zk-123

#更新节点
set  /zk-123 "d"

```
## 5.3 ZK配置文件
示例：
```shell

tickTime=2000
dataDir=E:/zookeeper/zookeeper-3.4.8 - colony/zookeeper-1/tmp/zookeeper/
clientPort=2181
initLimit=10
syncLimit=5
server.1=127.0.0.1:2888:3888
server.2=127.0.0.1:2889:3889
server.3=127.0.0.1:2890:3890
```
配置项说明：
简单列举，详细参考 http://www.aboutyun.com/forum.php?mod=viewthread&tid=13909

- clientPort: 客户端连接server的端口，即zk对外服务端口，一般设置为2181。
- dataDir : 把内存中的数据存储成快照文件snapshot的目录
- tickTime: ZK中的一个时间单元
- syncLimit: 如果Leader发出心跳包在syncLimit之后，还没有从Follower那里收到响应，那么就认为这个Follower已经不在线了。
 

## 5.4 ZK机制
### 5.4.1 Zookeeper工作原理
Zab协议 的全称是 Zookeeper Atomic Broadcast （Zookeeper原子广播）。ZAB协议定义了 选举（election）、发现（discovery）、同步（sync）、广播(Broadcast) 四个阶段；
选举阶段就是选举出leader。发现阶段follower节点向准leader推送自己的信息，接受准leader的newEpoch指令，检查newEpoch有效性,如果校验没有问题则正式进入一个新的leader统治时期（epoch）。同步阶段将Follower与Leader的数据进行同步，由Leader发起同步指令，最终保持集群数据的一致性；广播阶段，leader发起广播，Follower开始提交事务。

为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。zxid是一个64位的数字，它高32位用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的标识，代表当前leader，低32位用于递增计数。
在ZK集群中，Server有三种状态： 
- LOOKING：当前Server不知道leader是谁，正在搜寻
- LEADING：当前Server即为选举出来的leader
- FOLLOWING：leader已经选举出来，当前Server与之同步

当ZK的server挂掉半数以上，leader就认为集群不能再正常工作了；所以ZK集群一般为奇数个。 

### 5.4.2 ZK选主流程
ZK集群中每个Server启动，首先会投自己一票，然后向外对其他ZK发送报文，如果有响应则互相交换投票结果，如果结果无法确定leader是谁则继续投票。投票规则是优先投票给id最大的server，且不能重复投某个server。因此一个server若想做leader，它的id要足够大（通过配置文件配置），而且还有尽快和其他server建立通讯。


### 5.4.3 Broadcast(广播)
当客户端提交事务请求时Leader节点为每一个请求生成一个Proposal(提案)，将其发送给集群中所有的Follower节点，收到过半Follower的反馈后开始对事务进行提交；只需要得到过半的Follower节点反馈Ack（同意）就可以对事务进行提交；过半的Follower节点反馈Ack 后，leader发送commit消息同时自身也会完成事务提交，Follower 接收到 commit 消息后，会将事务提交。

Follower必须保证事务的顺序一致性的，也就是说先被发送的Proposal必须先被；消息广播使用了TCP协议进行通讯所有保证了接受和发送事务的顺序性。广播消息时Leader节点为每个Proposal分配一个全局递增的ZXID（事务ID），每个Proposal都按照ZXID顺序来处理。

如果我们连接上某个zk发送一个写请求，如果这个zk不是Leader，那么它会把接受到的请求进一步转发给Leader，然后leader就会执行上面的广播过程。而其他的zk就能同步写数据，保证数据一致。


## 5.5 ZK面试问题

- 脑裂：由于心跳超时（网络原因导致的）认为master死了，但其实master还存活着（假死），假死会发起新的master选举，选举出一个新的master。但是客户端还能和旧的master通信，导致一部分客户端连接旧master（直连）,一部分客户端连接新的master
- znode类型：临时无序，临时有序，持久无序，持久有序
- Zookeeper通知机制：client端会对某个znode建立一个watcher事件，当该znode发生变化时，这些client会收到zk的通知，然后client可以根据znode变化来做出业务上的改变等。
- 概述zk 工作原理：Zookeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。

# 6. dubbo

# 7. mycat

# 8. sentinel

# 9. rabbitMQ
## 1. rabbitMQ简介
`rabbitMQ`是基于`AMQP`协议的消息中间件，即`Advanced Message Queuing Protocol`，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。 AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）。基于AMQP协议的消息中间件还有`kafka`，`rocketMQ`等。还有另外一类基于jms协议的消息中间件（如activeMQ），这类MQ相对AMQP来说扩展性有所不足，因此大部分公司都会选择AMQP产品。而rabbitMQ以其安装部署简单，上手门槛低，功能丰富，集群易扩展，有强大的WEB管理页面，消息可靠投递机制等优点受广大开发人员欢迎。

介绍了这么多，或许有的小伙伴还是不太明白MQ的使用场景，MQ作用就六个字——异步，削峰，解耦。它在大型电子商务类网站，如京东、淘宝、去哪儿等网站有着深入的应用。比如一个下单流程，在不使用消息队列的情况下，用户的请求数据直接写入数据库，在高并发的情况下，会对数据库造成巨大的压力，同时也使得系统响应延迟加剧。在使用队列后，用户的请求发给队列后立即返回，后续处理交给队列，在业务逻辑上只需要做简单修改即可（如告诉用户系统确认订单中，等MQ处理完再更新订单状态），这只是一个简单的使用场景，MQ的用武之地还很多。
## 2. rabbitMQ成员角色
学习rabbtMQ我们先要弄清楚这几个概念：`exchange`,`queue`,`routing-key`,`binding-key`,`message`,`publisher`,`exchange`,`binding-key`,`Connection`,`Channel`,`consumer`,`broker`；下面对这些角色概念进行介绍。

消息的发送方被称作`publisher`（生产者），而消息的接收方被称作`consumer`(消费者)，而消息队列服务器实体就是`broker`（指`rabbitMQ`）；消费者或者生产者对rabbitMQ的一个连接被称作`Connection`（连接）,在rabbit的连接模型中，为了提高连接传输效率，采用了`Channel`（管道）这种方式实现多路复用，类似于Nio中的模型；我们知道建立一个TCP连接代价很大，因此TCP连接建立后最好不要断开`Connection`-`Channel`连接模型就是为了达到这种目的；一个消费者（生产者）使用一个`channel`消费（发送）消息，而多个`Channel`共用一个`Connection`。

一个生产者向rabbit投递消息，然后消费者消费这个消息的过程是这样的——生产者将消息投递给rabbit，在rabbit中`exchange`（交换机）首先会接收到这个消息，交换机相当于一个“分拣员”的角色，负责分拣消息，将这些消息存储到和自己绑定的`queue`（队列）中去，然后和队列绑定的消费者会消费这些消息。队列和交换机绑定通过一个`binding-key`（绑定键）来标记，而生产者投递消息给交换机的时候会指定一个`routing-key`（路由键），而交换机会根据路由和绑定键来判断将消息放到那些队列中去（扩展：kafka）。

在rabbit中交换机共有四种类型，下面对其类型和其消息路由规则做说明：
- `direct exchange`(直连交换机)：消息中的`routing-key`如果和`binding-key`一致， 交换器就将消息发到对应的队列中,`routing-key`要与`binding-key`完全匹配。
- `fanout exchange`(扇型交换机):扇型交换机会将交给自己的消息发到所有和自己绑定的队列中去，它不会去匹配`routing-key`和`binding-key`。
- `topic exchange`(主题交换机):主题交换机的`routing-key`匹配`binding-key`的方式支持模糊匹配， 以.分割单词，`*`匹配一个单词，`#`匹配多个单词，比如如路由键是`com.muggle.first` 能被`com.#`和`*.muggle.*`绑定键匹配。
- `headers exchange`(头交换机):类似主题交换机，但是头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。当交换机的`x-match`属性为`any`时，消息头的任意一个值被匹配就可以满足条件,当为`all`的时候，就需要消息头的所有值都匹配成功,这种交换机在实际生产中用的并不多。

## 3. springboot+rabbitMQ使用案例
本文的demo已经放到github上去了，有需要的小伙伴可以去拉下来（顺便求个star），地址： 。运行本项目之前请先安装好`rabbitMQ`，用`docker`安装的话，一个命令就搞定了，如果安装在windows上需要注意这几个坑——1.确保`Erlang`安装成功（安装过程中会提示），2.rabbitMQ的web管理插件需要另外安装，3. 注意用户权限配置。小伙伴可以参考这篇博客：`https://www.cnblogs.com/lykbk/p/erewererewr32434343.html`。这一节主要介绍怎么在springboot中集成使用rabbitMQ。后续章节会介绍，交换机、队列、消息等角色相关参数如何在项目中配置使用。

在正式使用前我们先来瞅瞅rabbitMQ的web管理界面，访问`http://localhost:15672/#/`登录后，你会看到`图1`这些东西：`Overview` 是对rabbitMQ整体情况统计的界面，`Connections`是对连接进行管理的界面，`Queues`是队列管理界面，`Admin`是用户管理界面，以此类推。

### 3.1 简单消息队列
springboot会默认为你创建一个`direct exchange`类型交换机，其名称为`""`空字符串，其路由键和绑定键都是队列名称，未指定交换机的队列都会绑定到这个交换机上去。我们就以这个最简单的消息队列开始来学习如何在项目中使用`rabbitMQ`。依赖如下：
```xml
 <dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
 </dependency>
 <dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

 <dependency>
    <groupId>org.projectlombok</groupId>
    <artifactId>lombok</artifactId>
    <optional>true</optional>
 </dependency>

 <dependency>
    <groupId>org.apache.commons</groupId>
    <artifactId>commons-text</artifactId>
    <version>1.2</version>
 </dependency>

 <dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-test</artifactId>
    <scope>test</scope>
 </dependency>
```
properties:
```properties
spring.rabbitmq.host=localhost
spring.rabbitmq.username=guest
spring.activemq.password=guest
```
注册两个交换机，一个用于传递String类型消息，一个传递Object类型的数据。项目启动后springboot会为你在 rabbitMQ 中创建两个队列，启动项目后打开 rabbitMQ 的 web 管理界面（以下简称管理界面）会在 Queues 中看到这两个队列的相关信息。
```java
@Component
public class QueueConfig {
    @Bean
    public Queue getSimpleQueue() {
        return new Queue("simple-queue");
    }

    @Bean
    public Queue getObjSimpleQueue() {
        return new Queue("obj-simple-queue");
    }
}
```
创建两个定时任务，向 rabbitMQ 投递消息，注意这里需要在启动类上加 `@EnableScheduling` 注解以启动定时任务，而 `Message` 是我创建的实体类：
```java
@Component
public class ScheduleHandler {
    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Scheduled(fixedRate = 6000)
    private void simpleQueueSchedule() {
        System.out.println("<<<<<<<<<<");

        rabbitTemplate.convertAndSend("simple-queue","ni----hao");
    }

    @Scheduled(fixedRate = 6000)
    private void objSimpleQueueSchedule() {
        System.out.println("<<<<<<<<<<");
        Message message = new Message();
        message.setTitle("hello");
        message.setContent("how are you ");
        rabbitTemplate.convertAndSend("obj-simple-queue",message);
    }

}
```
消费者消费消息：
```java
@Component
public class QueueMessageHandler {

    @RabbitListener(queues = { "simple-queue"})
    public void getSimpleQueueMessage(String msg){
        System.out.println(msg);
    }

    @RabbitListener(queues = { "obj-simple-queue"})
    public void getObjSimpleQueueMessage(Message msg){
        System.out.println(msg);
    }

}
```

`rabbitTemplate.convertAndSend()`方法是将数据序列化并写入队列中，而其使用的序列化协议自然是java序列化协议（使用 `ObjectInputStream` 和 `ObjectOutputStream` 读写），因此你如果调用这个方法则其实体类需要实现`Serializable`接口，而如果跨虚拟机还需要注意 `serialVersionUID`。如果跨平台了，那么最好使用其他序列化的方式,序列化反序列化配置在后文介绍。

### 3.2 推模式和拉模式
对消费端而言使用`@RabbitListener`监听器获取MQ消息的方式称为`推模式`，我们还可以使用拉模式，当我们需要一条消息的时候才从队列中拉一条消息出来，使用的方法为 `rabbitTemplate.receiveAndConvert()`，如：
```
  Message o = ((Message) rabbitTemplate.receiveAndConvert("obj-simple-queue"));
```

### 3.3 direct exchange 直连交换机
直连交换机，需要注册一个 `DirectExchange` , `Queue` , `Binding` 。`Bingding` 负责将 `DirectExchange` 和 `Queue` 绑定并指定 `routingKey` 生产者生产消息的时候也需要指定 `routingKey`。下面看示例：
```java
//  生产端配置
    @Bean("directQueueFirst")
    public Queue directQueueFirst() {
        return new Queue("first-direct-queue");
    }

    @Bean("directQueueSecond")
    public Queue directQueueSecond() {
        return QueueBuilder.durable("second-direct-queue").build();
    }
    @Bean("directExchange")
    public DirectExchange directExchange() {
        return new DirectExchange("direct-exchange");
    }
    
    @Bean
    public Binding bingQueueFirstToDirect(@Qualifier("directQueueFirst") Queue queue, @Qualifier("directExchange") DirectExchange exchange) {
        return BindingBuilder.bind(queue).to(exchange).with("first-key");
    }

    @Bean
    public Binding bingQueueSecondToDirect(@Qualifier("directQueueSecond") Queue queue, @Qualifier("directExchange") DirectExchange exchange) {
        return BindingBuilder.bind(queue).to(exchange).with("second-key");
    }
    
//  生产者发送消息
@Component
public class ScheduleHandler {

    @Scheduled(fixedRate = 6000)
    private void directMessageScheduleFirst() {
        Message message = new Message();
        message.setTitle("hello");
        message.setContent("how are you for direct first");
        rabbitTemplate.convertAndSend("direct-exchange","first-key",message);
    }

    @Scheduled(fixedRate = 6000)
    private void directMessageScheduleSecond() {
        Message message = new Message();
        message.setTitle("hello");
        message.setContent("how are you for direct second");
        rabbitTemplate.convertAndSend("topic-exchange","second-key",message);
    }
}
@Component
public class QueueMessageHandler {
//  消费端
    @RabbitListener(queues = { "first-direct-queue"})
    public void firstDirectMessageQueue(Message msg){
        System.out.println(msg);
    }

    @RabbitListener(queues = { "second-direct-queue"})
    public void secondDirectMessageQueue(Message msg){
        System.out.println(msg);
    }
}
```
值得注意的是，springboot为了使我们的代码可读性更好，还非常贴心的提供 `Exchange`,`Binding`,`Queue`的`Builder`（建造者），因此你可以使用它们对应建造者，也可以使用直接 new 的方式进行创建。另外创建的这些 exchange queue 都能在管理界面上看到，如图 2 ，图 3 ：

### fanout exchange 扇型交换机
使用上和 direct exchange 大同小异，只不过不需要指定路由键，而且所有和它绑定的队列都会收到消息，直接上代码：
```java
// 生产者配置
    @Bean("fanoutQueueFirst")
    public Queue fanoutQueueFirst() {
        return new Queue("first-fanout-queue");
    }

    @Bean("fanoutQueueSecond")
    public Queue fanoutQueueSecond() {
        return new Queue("second-fanout-queue");
    }

    @Bean("fanoutExchange")
    public FanoutExchange fanoutExchange() {
        return new FanoutExchange("fanout-exchange");
    }

    @Bean
    public Binding bingQueueFirstToExchange(@Qualifier("fanoutQueueFirst") Queue queue, @Qualifier("fanoutExchange") FanoutExchange exchange) {
        return BindingBuilder.bind(queue).to(exchange);
    }

    @Bean
    public Binding bingQueueSecondToExchange(@Qualifier("fanoutQueueSecond") Queue queue, @Qualifier("fanoutExchange") FanoutExchange exchange) {
        return BindingBuilder.bind(queue).to(exchange);
    }
//  生产者发消息，注意这里虽然填了routingKey 但是是无效的
    @Scheduled(fixedRate = 6000)
    private void directMessageScheduleFirst() {
        Message message = new Message();
        message.setTitle("hello");
        message.setContent("how are you for direct first");
        rabbitTemplate.convertAndSend("direct-exchange","first-key",message);
    }
//  消费者，两个队列都能收到同一份消息

    @RabbitListener(queues = { "first-fanout-queue"})
    public void firstFanoutQueue(Message msg){
        System.out.println(msg);
    }

    @RabbitListener(queues = { "second-fanout-queue"})
    public void secondFanoutQueue(Message msg){
        System.out.println(msg);
    }
```

### 主题交换机  Topic
前文介绍了主题交换机的路由方式，注意我代码中的路由键设置，这里我设置两个`bingding-key` 分别是 `com.muggle.first` 和 `com.#` 我用 `routing-key` 为 `com.muggle.test` 发消息这两个队列都能接收到

```java
    @Bean("topicQueueFirst")
    public Queue topicQueueFirst() {
        return new Queue("first-topic-queue");
    }

    @Bean("topicQueueSecond")
    public Queue topicQueueSecond() {
        return new Queue("second-topic-queue");
    }

    @Bean
    public Binding bindTopicFirst(@Qualifier("topicQueueFirst") Queue queue, @Qualifier("topicExchange") TopicExchange exchange) {
        return BindingBuilder.bind(queue).to(exchange).with("com.muggle.first");
    }

    @Bean
    public Binding bindTopicSecond(@Qualifier("topicQueueFirst") Queue queue, @Qualifier("topicExchange") TopicExchange exchange) {
        return BindingBuilder.bind(topicQueueFirst()).to(topicExchange()).with("com.#");
    }
    
    @Scheduled(fixedRate = 6000)
    private void topicMessage() {
        Message message = new Message();
        message.setTitle("hello");
        message.setContent("how are you for topic test");
        rabbitTemplate. convertAndSend("topic-exchange","com.muggle.test",message);
    }
    
    
    @RabbitListener(queues = { "first-topic-queue"})
    public void firstTopicMessageQueue(Message msg){
        System.out.println(msg);
    }

    @RabbitListener(queues = { "second-topic-queue"})
    public void secondTopicMessageQueue(Message msg){
        System.out.println(msg);
    }

```
好了，三种常用交换机的使用已经介绍完毕；有疑问的小伙伴可以在评论区留言探讨。关于队列和交换机的进阶使用技巧，且听下回分解。

# 4. rabbitMQ 进阶和 springboot 配置
前文我们介绍了在springboot中rabbitMQ的基本使用，现在进一步介绍rabbit的一些配置。
## 4.1 持久化
RabbitMQ通过消息持久化来保证消息的可靠性——为了保证RabbitMQ在退出或者发生异常情况下数据不会丢失，需要将 queue ，exchange 和 Message 都持久化。下面分别介绍它们持久化配置的方式。

对于 queue ，exchange 在创建的时候都会提供一个参数用以设置是否持久化，而如果使用它们对应的建造者而不是new，就能很清晰的看到是怎么指定持久化的：
```java
//  创建 queue 指定为非持久化
    QueueBuilder.nonDurable("xxx").build();
//  指定非持久化
     return QueueBuilder.durable("second-direct-queue").build();
//  durable 为true则是持久化，false非持久化
    ExchangeBuilder.topicExchange("topic").durable(true).build();
```
这里需要注意一个地方，那么你直接在原队列的基础上添加属性是会报错的，它会告诉你队列已经存在。需要你手动打开管理界面把那个队列删除掉，然后重启项目。

你如果将 queue 的持久化标识 durable 设置为true ,则代表是一个持久的队列，那么在服务重启之后，也会存在，因为服务会把持久化的 queue 存放在硬盘上，当服务重启的时候，会重新什么之前被持久化的queue；但是里面的消息是否为持久化还需要看消息是否做了持久化设置。exchange 的持久化和 Queue 一样将交换机保存在磁盘，重启后这个交换机还会存在。

那么消息如何持久化呢？在springboot中需要借助`MessagePostProcessor` 消息加工器对消息进行加工 rabbitMQ 才能知道这个消息是不是要持久化，`MessagePostProcessor`还有其他的很多作用，在后文会介绍。下面看如何进行消息的持久化。
创建`MessagePostProcessor`类：
```JAVA
public class MyMessagePostProcessor implements MessagePostProcessor {
    
    @Override
    public Message postProcessMessage(Message message) throws AmqpException {
        message.getMessageProperties().setDeliveryMode(MessageDeliveryMode.PERSISTENT);
        return message;
    }
}
```
生产者通过`MessagePostProcessor`发送消息：
```java
 @Scheduled(fixedRate = 1000)
    private void sendMessageForDlx() {
        rabbitTemplate.convertAndSend("exchange","routing key","mesage",new MyMessagePostProcessor());
    }
```
消息持久化过程：
>  写入文件前会有一个Buffer,大小为1M,数据在写入文件时，首先会写入到这个Buffer，如果Buffer已满，则会将Buffer写入到文件（未必刷到磁盘）。
有个固定的刷盘时间：25ms,也就是不管Buffer满不满，每个25ms，Buffer里的数据及未刷新到磁盘的文件内容必定会刷到磁盘。
每次消息写入后，如果没有后续写入请求，则会直接将已写入的消息刷到磁盘：使用Erlang的receive x after 0实现，只要进程的信箱里没有消息，则产生一个timeout消息，而timeout会触发刷盘操作。
原文链接：https://blog.csdn.net/u013256816/article/details/60875666

## TTL
RabbitMQ可以对消息和队列设置TTL(消息的过期时间)，消息在队列的生存时间一旦超过设置的TTL值，就称为dead message， 消费者将无法再收到该消息。
### 在队列上设置消息过期时间
设置队列过期加一个参数 `x-message-ttl` 就可以搞定，同样记得先把原队列在管理界面删除再启动项目，才会创建队列成功。创建持久化队列：
```java
    Queue build = QueueBuilder.durable("queue")
//      消息过期的时间
                .withArgument("x-message-ttl",5000L).build();
```
这种方式设置的过期属性特性是一旦消息过期，就会从队列中抹去（及时性）。

### 通过`MessagePostProcessor`设置消息过期时间

把原来的 `MyMessagePostProcessor` 代码拿过来加一个参数就行了：
```java
public class MyMessagePostProcessor implements MessagePostProcessor {
    private String expirTime;

    public MyMessagePostProcessor(String expirTime){
        this.expirTime=expirTime;
    }
    @Override
    public Message postProcessMessage(Message message) throws AmqpException {
//        设置过期时间
        message.getMessageProperties().setExpiration(expirTime);
//        设置消息持久化
        message.getMessageProperties().setDeliveryMode(MessageDeliveryMode.PERSISTENT);
        return message;
    }
```
这种方式设置的过期时间即使消息过期，也不一定会马上从队列中抹去，它会等轮到这个消息即将投递到消费者之前进行判定。如果过期就丢弃，不再投递给消费者

## 优先级
优先级分为消息优先级和队列优先级，队列优先级高的会先被处理，消息优先级高的会先被消费，队列优先级配置参数为`x-max-priority`,配置方式为：
```java
Queue build = QueueBuilder.durable("queue").withArgument("x-max-priority",10)
```
配置的数字越大，优先级越高默认优先级为0，消息优先级设置也一样。消息的优先级还是通过 `MessagePostProcessor` 来设置：
```java
    @Override
    public Message postProcessMessage(Message message) throws AmqpException {
        message.getMessageProperties().setPriority(5);
        return message;
    }
```

### 死信队列
通过参数`x-dead-letter-exchange`将一个队列设置为死信队列。死信队列的机制是，如果一条消息成为死信 `dead message`，它不是直接丢弃掉，而是在转发到另外一个交换机，由这个交换机来处理这条死信。利用这一机制可达到消息延时的效果——先注册一个没有消费者且设置了过期时间的队列死信队列，投递给这个队列的消息因为没有消费者过一段时间后就会过期成为死信，过期的死信转发到对应的死信交换机里面去分配给其他队列去处理这些消息。上代码：
```java
//  注册死信队列
    @Bean("dlxQueue")
    public Queue dlxQueue(){
//        new Queue("text",true, false, false,new HashMap<>())
//        x-dead-letter-exchange声明了队列里的死信转发到的交换机名称
        Queue build = QueueBuilder.durable("dlx-queue").withArgument("x-dead-letter-exchange", "gc-exchange")
//                dead letter携带的routing-key
                .withArgument("x-dead-letter-routing-key", "dlx-key")
//                消息在过期的时间
                .withArgument("x-message-ttl",5000L).build();
        return build;
    }
//  队列的交换机    
    @Bean("dlxExchange")
    public DirectExchange  dlxExchange(){
//        ExchangeBuilder.topicExchange().durable()
        return new DirectExchange("dlx-exchange");
    }
//  真正处理消息的队列
    @Bean("gcQueue")
    public Queue gcQueue(){
        Queue build = QueueBuilder.durable("gc-queue").build();
        return build;
    }
//  略
    @Bean("dlxExchange")
    public DirectExchange  dlxExchange(){
//        ExchangeBuilder.topicExchange().durable()
        return new DirectExchange("dlx-exchange");
    }

    @Bean("gcExchange")
    public DirectExchange  gcExchange(){
        return new DirectExchange("gc-exchange");
    }

    @Bean
    public Binding bindingGcQueue(@Qualifier("gcQueue") Queue queue,@Qualifier("gcExchange")DirectExchange exchange){
        return BindingBuilder.bind(queue).to(exchange).with("dlx-key");
    }

    @Bean
    public Binding bindingDlxQueue(@Qualifier("dlxQueue") Queue queue,@Qualifier("dlxExchange")DirectExchange exchange){
        return BindingBuilder.bind(queue).to(exchange).with("test-dlx");
    }
```
队列和交换机都注册好了，然后我们分别向 `dlx-queue` 分配一个生产者，向 `gc-queue` 分配一个消费者：
```java
 @Scheduled(fixedRate = 1000)
    private void sendMessageForDlx() {
        rabbitTemplate.convertAndSend("dlx-exchange","test-dlx","test");
    }
    
    @RabbitListener(queues = { "gc-queue"})
    public void gcMessage(String message){
        System.out.println(message);
    }
```
打开管理界面界面你能看到消息的流转过程`dlx-queue`被写入消息，而 `gc-queue` 却没有消息,然后 `dlx-queue` 消息减少而`gc-queue` 消息增多。最终消息在`gc-queue` 被消费。
### 生产者确认机制

### 消费者确认机制
### 事务
### 消息分发
### 消息的顺序性

如果 `RabbitMQ` 没有收到回执并检测到消费者的RabbitMQ连接断开，则 `RabbitMQ` 会将该消息发送给其他消费者（如果存在多个消费者）进行处理。这里不存在 `timeout` 概念，一个消费者处理消息时间再长也不会导致该消息被发送给其他消费者，除非它的RabbitMQ连接断开。


### 重复消费等问题
### 备胎机

## rabbitMQ 进阶
### 存储机制
### 队列的结构
### 联邦机
### 监控数据

# spring

# spring cloud
本章节主要对 spring cloud组件做整体的介绍，部分组件会分析其原理。
## 
# linux&docker

本人Linux很菜所以暂时不写，找个大手写，以免误导他人

# 框架

# 工具

## idea

## git
### 常用指令
### git subtree

## maven

### 常用命令

> 1. 创建Maven的普通java项目： 
>    mvn archetype:create 
>    -DgroupId=packageName 
>    -DartifactId=projectName  
> 2. 创建Maven的Web项目：   
>    mvn archetype:create 
>    -DgroupId=packageName    
>    -DartifactId=webappName 
>    -DarchetypeArtifactId=maven-archetype-webapp    
> 3. 编译源代码： mvn compile 
> 4. 编译测试代码：mvn test-compile    
> 5. 运行测试：mvn test   
> 6. 产生site：mvn site   
> 7. 打包：mvn package   
> 8. 在本地Repository中安装jar：mvn install 
> 9. 清除产生的项目：mvn clean   
> 10. 生成eclipse项目：mvn eclipse:eclipse  
> 11. 生成idea项目：mvn idea:idea  
> 12. 组合使用goal命令，如只打包不测试：mvn -Dtest package   
> 13. 编译测试的内容：mvn test-compile  
> 14. 只打jar包: mvn jar:jar  
> 15. 只测试而不编译，也不测试编译：mvn test -skipping compile -skipping test-compile 
>       ( -skipping 的灵活运用，当然也可以用于其他组合命令)  
> 16. 清除eclipse的一些系统设置:mvn eclipse:clean  

## gradle

# 不常见问题汇总

# 作者有话说

github地址


本人微信：